{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. import & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from visual import *\n",
    "from plotter import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Input,  MaxPooling2D, GlobalMaxPooling2D, ZeroPadding2D, AveragePooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, add\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def load_images(path, names):\n",
    "    \n",
    "    images= [ PIL.Image.open(path + name) for name in names ]\n",
    "    #     print([i.size for i in images])\n",
    "    \n",
    "    return images\n",
    "\n",
    "def images2numpy(images, size):\n",
    "\n",
    "    output = [np.array(im.resize(size)) for im in images]\n",
    "    \n",
    "    output = np.array(output)\n",
    "    \n",
    "    return output\n",
    " \n",
    "def get_images_and_preprocessing(img_size):\n",
    "    \n",
    "    CSV_TRAIN_PATH = \"./German-Traffic-Sign/train.csv\"\n",
    "    CSV_TEST_PATH = \"./German-Traffic-Sign/test.csv\"\n",
    "    IMG_PATH = \"./German-Traffic-Sign/\"\n",
    "    IMG_SIZE = (img_size,img_size)\n",
    "\n",
    "    name_train_caption = load_data(CSV_TRAIN_PATH)\n",
    "    name_test_caption = load_data(CSV_TEST_PATH)\n",
    "    names_train = name_train_caption['Path']\n",
    "    names_test = name_test_caption['Path']\n",
    "    \n",
    "    images_train = load_images(IMG_PATH,names_train)\n",
    "    images_test = load_images(IMG_PATH,names_test)\n",
    "    np_train_images = images2numpy(images_train,IMG_SIZE)\n",
    "    np_test_images = images2numpy(images_test,IMG_SIZE)\n",
    "   \n",
    "    label_train_caption = load_data(CSV_TRAIN_PATH)\n",
    "    label_test_caption = load_data(CSV_TEST_PATH)\n",
    "    np_train_labels = label_train_caption['ClassId'].tolist()\n",
    "    np_test_labels = label_test_caption['ClassId'].tolist()\n",
    "\n",
    "    train_images = np_train_images / 255.\n",
    "    test_images = np_test_images / 255.\n",
    "    \n",
    "    train_labels = to_categorical(np_train_labels, 43)\n",
    "    test_labels = to_categorical(np_test_labels, 43)\n",
    "    \n",
    "    return train_images, test_images, train_labels, test_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28\n",
    "\n",
    "CSV_TRAIN_PATH = \"./German-Traffic-Sign/train.csv\"\n",
    "CSV_TEST_PATH = \"./German-Traffic-Sign/test.csv\"\n",
    "IMG_PATH = \"./German-Traffic-Sign/\"\n",
    "IMG_SIZE = (img_size,img_size)\n",
    "    \n",
    "label_train_caption = load_data(CSV_TRAIN_PATH)\n",
    "label_test_caption = load_data(CSV_TEST_PATH)\n",
    "np_labels_train = label_train_caption['ClassId'].tolist()\n",
    "np_labels_test = label_test_caption['ClassId'].tolist()\n",
    "\n",
    "# name_train_caption = load_data(CSV_TRAIN_PATH)\n",
    "# name_test_caption = load_data(CSV_TEST_PATH)\n",
    "# names_train = name_train_caption['Path']\n",
    "# names_test = name_test_caption['Path']\n",
    "\n",
    "# images_train = load_images(IMG_PATH,names_train)\n",
    "# images_test = load_images(IMG_PATH,names_test)\n",
    "# np_train_images = images2numpy(images_train,IMG_SIZE)\n",
    "# np_test_images = images2numpy(images_test,IMG_SIZE)\n",
    "\n",
    "\n",
    "my_set = set(np_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MLP(다층 퍼셉트론 모델)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도 : 0.85\n",
    "epoch = 50, batch_size = 256, image_size = 28, layer = 3 (relu, relu, softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 28, 28, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 2352)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               1204736   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 1,347,115\n",
      "Trainable params: 1,347,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "154/154 - 2s - loss: 2.1855 - accuracy: 0.4577 - val_loss: 1.8530 - val_accuracy: 0.4949\n",
      "Epoch 2/50\n",
      "154/154 - 1s - loss: 0.9803 - accuracy: 0.7581 - val_loss: 1.1264 - val_accuracy: 0.7236\n",
      "Epoch 3/50\n",
      "154/154 - 1s - loss: 0.6650 - accuracy: 0.8343 - val_loss: 0.9592 - val_accuracy: 0.7519\n",
      "Epoch 4/50\n",
      "154/154 - 1s - loss: 0.5000 - accuracy: 0.8759 - val_loss: 0.8459 - val_accuracy: 0.8020\n",
      "Epoch 5/50\n",
      "154/154 - 1s - loss: 0.3950 - accuracy: 0.9032 - val_loss: 0.8000 - val_accuracy: 0.8128\n",
      "Epoch 6/50\n",
      "154/154 - 1s - loss: 0.3641 - accuracy: 0.9099 - val_loss: 0.8280 - val_accuracy: 0.8254\n",
      "Epoch 7/50\n",
      "154/154 - 1s - loss: 0.3036 - accuracy: 0.9275 - val_loss: 0.7939 - val_accuracy: 0.8303\n",
      "Epoch 8/50\n",
      "154/154 - 1s - loss: 0.2808 - accuracy: 0.9305 - val_loss: 0.8554 - val_accuracy: 0.8198\n",
      "Epoch 9/50\n",
      "154/154 - 2s - loss: 0.2504 - accuracy: 0.9384 - val_loss: 0.8593 - val_accuracy: 0.8200\n",
      "Epoch 10/50\n",
      "154/154 - 1s - loss: 0.2381 - accuracy: 0.9422 - val_loss: 0.7927 - val_accuracy: 0.8356\n",
      "Epoch 11/50\n",
      "154/154 - 1s - loss: 0.2209 - accuracy: 0.9443 - val_loss: 0.7799 - val_accuracy: 0.8493\n",
      "Epoch 12/50\n",
      "154/154 - 1s - loss: 0.1922 - accuracy: 0.9542 - val_loss: 1.2428 - val_accuracy: 0.7911\n",
      "Epoch 13/50\n",
      "154/154 - 1s - loss: 0.1748 - accuracy: 0.9582 - val_loss: 0.8248 - val_accuracy: 0.8350\n",
      "Epoch 14/50\n",
      "154/154 - 1s - loss: 0.1673 - accuracy: 0.9589 - val_loss: 0.9795 - val_accuracy: 0.8188\n",
      "Epoch 15/50\n",
      "154/154 - 1s - loss: 0.1682 - accuracy: 0.9576 - val_loss: 0.9884 - val_accuracy: 0.8378\n",
      "Epoch 16/50\n",
      "154/154 - 1s - loss: 0.1574 - accuracy: 0.9612 - val_loss: 0.8186 - val_accuracy: 0.8558\n",
      "Epoch 17/50\n",
      "154/154 - 1s - loss: 0.1529 - accuracy: 0.9598 - val_loss: 0.8915 - val_accuracy: 0.8451\n",
      "Epoch 18/50\n",
      "154/154 - 1s - loss: 0.1406 - accuracy: 0.9642 - val_loss: 0.9866 - val_accuracy: 0.8304\n",
      "Epoch 19/50\n",
      "154/154 - 1s - loss: 0.1202 - accuracy: 0.9698 - val_loss: 0.8166 - val_accuracy: 0.8612\n",
      "Epoch 20/50\n",
      "154/154 - 1s - loss: 0.1106 - accuracy: 0.9730 - val_loss: 0.8100 - val_accuracy: 0.8620\n",
      "Epoch 21/50\n",
      "154/154 - 2s - loss: 0.1221 - accuracy: 0.9675 - val_loss: 0.9520 - val_accuracy: 0.8497\n",
      "Epoch 22/50\n",
      "154/154 - 1s - loss: 0.1130 - accuracy: 0.9712 - val_loss: 0.9016 - val_accuracy: 0.8584\n",
      "Epoch 23/50\n",
      "154/154 - 2s - loss: 0.0913 - accuracy: 0.9774 - val_loss: 1.1220 - val_accuracy: 0.8203\n",
      "Epoch 24/50\n",
      "154/154 - 2s - loss: 0.1265 - accuracy: 0.9657 - val_loss: 1.1280 - val_accuracy: 0.8194\n",
      "Epoch 25/50\n",
      "154/154 - 1s - loss: 0.0908 - accuracy: 0.9750 - val_loss: 1.0276 - val_accuracy: 0.8392\n",
      "Epoch 26/50\n",
      "154/154 - 2s - loss: 0.0888 - accuracy: 0.9771 - val_loss: 0.9335 - val_accuracy: 0.8614\n",
      "Epoch 27/50\n",
      "154/154 - 2s - loss: 0.0695 - accuracy: 0.9822 - val_loss: 0.9372 - val_accuracy: 0.8624\n",
      "Epoch 28/50\n",
      "154/154 - 2s - loss: 0.0861 - accuracy: 0.9775 - val_loss: 0.9889 - val_accuracy: 0.8604\n",
      "Epoch 29/50\n",
      "154/154 - 2s - loss: 0.0681 - accuracy: 0.9824 - val_loss: 0.9137 - val_accuracy: 0.8661\n",
      "Epoch 30/50\n",
      "154/154 - 2s - loss: 0.0742 - accuracy: 0.9807 - val_loss: 1.0685 - val_accuracy: 0.8416\n",
      "Epoch 31/50\n",
      "154/154 - 2s - loss: 0.1238 - accuracy: 0.9661 - val_loss: 1.3209 - val_accuracy: 0.8047\n",
      "Epoch 32/50\n",
      "154/154 - 2s - loss: 0.0779 - accuracy: 0.9794 - val_loss: 0.8796 - val_accuracy: 0.8709\n",
      "Epoch 33/50\n",
      "154/154 - 2s - loss: 0.0567 - accuracy: 0.9852 - val_loss: 0.9229 - val_accuracy: 0.8633\n",
      "Epoch 34/50\n",
      "154/154 - 2s - loss: 0.0620 - accuracy: 0.9836 - val_loss: 0.9870 - val_accuracy: 0.8606\n",
      "Epoch 35/50\n",
      "154/154 - 2s - loss: 0.0603 - accuracy: 0.9840 - val_loss: 1.0671 - val_accuracy: 0.8504\n",
      "Epoch 36/50\n",
      "154/154 - 2s - loss: 0.0699 - accuracy: 0.9808 - val_loss: 0.9192 - val_accuracy: 0.8748\n",
      "Epoch 37/50\n",
      "154/154 - 2s - loss: 0.0624 - accuracy: 0.9830 - val_loss: 1.0912 - val_accuracy: 0.8568\n",
      "Epoch 38/50\n",
      "154/154 - 2s - loss: 0.0945 - accuracy: 0.9726 - val_loss: 1.2344 - val_accuracy: 0.8461\n",
      "Epoch 39/50\n",
      "154/154 - 2s - loss: 0.0538 - accuracy: 0.9849 - val_loss: 1.0697 - val_accuracy: 0.8484\n",
      "Epoch 40/50\n",
      "154/154 - 2s - loss: 0.0556 - accuracy: 0.9842 - val_loss: 1.0412 - val_accuracy: 0.8644\n",
      "Epoch 41/50\n",
      "154/154 - 2s - loss: 0.0769 - accuracy: 0.9791 - val_loss: 1.0772 - val_accuracy: 0.8541\n",
      "Epoch 42/50\n",
      "154/154 - 2s - loss: 0.0476 - accuracy: 0.9871 - val_loss: 0.9831 - val_accuracy: 0.8743\n",
      "Epoch 43/50\n",
      "154/154 - 2s - loss: 0.0317 - accuracy: 0.9910 - val_loss: 0.9555 - val_accuracy: 0.8791\n",
      "Epoch 44/50\n",
      "154/154 - 2s - loss: 0.0322 - accuracy: 0.9916 - val_loss: 1.1341 - val_accuracy: 0.8587\n",
      "Epoch 45/50\n",
      "154/154 - 2s - loss: 0.0622 - accuracy: 0.9821 - val_loss: 1.0733 - val_accuracy: 0.8648\n",
      "Epoch 46/50\n",
      "154/154 - 2s - loss: 0.0481 - accuracy: 0.9864 - val_loss: 1.1785 - val_accuracy: 0.8625\n",
      "Epoch 47/50\n",
      "154/154 - 2s - loss: 0.0622 - accuracy: 0.9827 - val_loss: 1.2127 - val_accuracy: 0.8559\n",
      "Epoch 48/50\n",
      "154/154 - 2s - loss: 0.0225 - accuracy: 0.9943 - val_loss: 1.0595 - val_accuracy: 0.8735\n",
      "Epoch 49/50\n",
      "154/154 - 2s - loss: 0.0478 - accuracy: 0.9865 - val_loss: 1.2825 - val_accuracy: 0.8499\n",
      "Epoch 50/50\n",
      "154/154 - 2s - loss: 0.0589 - accuracy: 0.9830 - val_loss: 1.1627 - val_accuracy: 0.8552\n",
      "395/395 [==============================] - 1s 2ms/step - loss: 1.1627 - accuracy: 0.8552: 0s - loss:\n",
      "\n",
      "Test Loss : 1.1627 | Test Accuracy : 0.8551860451698303\n",
      "예측한 Test Data 클래스 :  [16  1 38 ... 15  7 10]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def MLP(img_size):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(img_size, img_size, 3)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=512,activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(units=256,activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(units=43,activation='softmax'))\n",
    "\t\n",
    "    return model\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    train_images, test_images, train_labels, test_labels = get_images_and_preprocessing(28)\n",
    "    \n",
    "    print(train_images.shape)\n",
    "    print(type(train_images))\n",
    "    \n",
    "    \n",
    "    # 지시사항 2에서 설정한 모델을 불러옵니다.\n",
    "    model = MLP(28)\n",
    "    \n",
    "    # 모델의 구조를 확인합니다.\n",
    "    model.summary()\n",
    "    \n",
    "    # 컴파일러를 설정합니다.\n",
    "    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    # fit 함수를 사용하여 모델을 학습합니다.\n",
    "    # 학습 수행 시 정보는 history에 저장합니다.\n",
    "    history = model.fit(train_images, train_labels, epochs=50, batch_size=256,validation_data=(test_images, test_labels),verbose=2)\n",
    "    \n",
    "    # evaluate 함수를 사용하여 테스트 데이터의 결과값을 저장합니다.\n",
    "    loss, test_acc = model.evaluate(test_images,test_labels)\n",
    "    \n",
    "    print('\\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))\n",
    "    print('예측한 Test Data 클래스 : ',model.predict_classes(test_images))\n",
    "    \n",
    "    Visulaize([('MLP', history)], 'loss')\n",
    "    \n",
    "    return test_acc\n",
    "\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도 : 0.91\n",
    "epoch = 20, batch_size = 256, image_size = 28, Conv = 3 (relu, relu, relu), Dense = 1(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def CNN(img_size):\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(img_size,img_size,3)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding=\"SAME\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D(2,padding=\"VALID\"))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding=\"SAME\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D(2, padding=\"VALID\"))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding=\"SAME\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D(2, padding=\"VALID\"))\n",
    "    \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(43, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n",
    "def main():\n",
    "    \n",
    "    train_images, test_images, train_labels, test_labels = get_images_and_preprocessing(28)\n",
    "    \n",
    "    print(train_images.shape)\n",
    "    print(type(train_images))\n",
    "    \n",
    "    \n",
    "    # 지시사항 2에서 설정한 모델을 불러옵니다.\n",
    "    model = CNN(28)\n",
    "    \n",
    "    # 모델의 구조를 확인합니다.\n",
    "    model.summary()\n",
    "    \n",
    "    # 컴파일러를 설정합니다.\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "    model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    # fit 함수를 사용하여 모델을 학습합니다.\n",
    "    # 학습 수행 시 정보는 history에 저장합니다.\n",
    "    history = model.fit(train_images,train_labels, epochs=20, batch_size=256, validation_data=(test_images, test_labels), verbose = 2)\n",
    "    \n",
    "    # evaluate 함수를 사용하여 테스트 데이터의 결과값을 저장합니다.\n",
    "    loss, test_acc = model.evaluate(test_images,test_labels, verbose=2)\n",
    "    \n",
    "    print('\\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))\n",
    "    print('예측한 Test Data 클래스 : ',model.predict_classes(test_images))\n",
    "    \n",
    "    Visulaize([('CNN', history)], 'loss')\n",
    "    \n",
    "    Plotter(test_images, model)\n",
    "    \n",
    "    return test_acc\n",
    "\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도 : 0.46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def LeNet(img_size):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    '''\n",
    "    지시사항 1번\n",
    "    LeNet 구조를 완성하세요.\n",
    "    '''\n",
    "    # Conv 1 Layer\n",
    "    model.add(Conv2D(filters=6, kernel_size=5, strides=1, activation=tf.nn.relu, input_shape=(img_size,img_size,3)))\n",
    "    \n",
    "    # Sub Sampling Layer (Max Pooling)\n",
    "    model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "    \n",
    "    # Conv 1 Layer\n",
    "    model.add(Conv2D(filters=16, kernel_size=5, strides=1, activation=tf.nn.relu, input_shape=(16,16,3)))\n",
    "            \n",
    "    \n",
    "    # Sub Sampling Layer (Max Pooling)\n",
    "    model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "    \n",
    "    # Fully Connected (FC) Layer와 연결하기 위한 Flatten\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # FC1 Layer \n",
    "    model.add(Dense(units=120, activation=tf.nn.relu))\n",
    "    \n",
    "    \n",
    "    # FC2 Layer\n",
    "    model.add(Dense(units=84, activation=tf.nn.relu))\n",
    "    \n",
    "    \n",
    "    # Output Softmax\n",
    "    model.add(Dense(units=43, activation=tf.nn.softmax))\n",
    "    \n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n",
    "def main():\n",
    "    \n",
    "    train_images, test_images, train_labels, test_labels = get_images_and_preprocessing(224)\n",
    "\n",
    "    print(train_images.shape)\n",
    "    print(type(train_images))\n",
    "    \n",
    "    \n",
    "    # 지시사항 2에서 설정한 모델을 불러옵니다.\n",
    "    model = LeNet(224)\n",
    "    \n",
    "    # 모델의 구조를 확인합니다.\n",
    "    model.summary()\n",
    "    \n",
    "    # 컴파일러를 설정합니다.\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "    model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    # fit 함수를 사용하여 모델을 학습합니다.\n",
    "    # 학습 수행 시 정보는 history에 저장합니다.\n",
    "    history = model.fit(train_images,train_labels, epochs=5, batch_size=2, validation_data=(test_images, test_labels), verbose = 2)\n",
    "    \n",
    "    # evaluate 함수를 사용하여 테스트 데이터의 결과값을 저장합니다.\n",
    "    loss, test_acc = model.evaluate(test_images,test_labels, verbose=2)\n",
    "    \n",
    "    print('\\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))\n",
    "    print('예측한 Test Data 클래스 : ',model.predict_classes(test_images)[:10])\n",
    "    \n",
    "    Visulaize([('LeNet', history)], 'loss')\n",
    "     \n",
    "#     오류해결해야함\n",
    "#     Plotter(test_images, model)\n",
    "    \n",
    "    return test_acc\n",
    "\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. VGGNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도 : 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def conv(filters, kernel_size = 3, activation= tf.nn.relu, padding= 'same'):\n",
    "    return keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, activation= activation, padding= padding)\n",
    "\n",
    "def VGG16(img_size):\n",
    "    # Sequential 모델 선언\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    '''\n",
    "    지시사항 1번\n",
    "    3 x 3 convolution만을 사용하여 VGG16 Net을 완성하세요.\n",
    "    '''\n",
    "    # 첫 번째 Conv Block\n",
    "    # 입력 Shape는 ImageNet 데이터 세트의 크기와 같은 RGB 영상 (224 x 224 x 3)입니다\n",
    "    model.add(Input((224, 224, 3)))\n",
    "    model.add(conv(64))\n",
    "    model.add(conv(64))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    \n",
    "    # 두 번째 Conv Block\n",
    "    model.add(conv(128))\n",
    "    model.add(conv(128))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    \n",
    "    # 세 번째 Conv Block\n",
    "    model.add(conv(256))\n",
    "    model.add(conv(256))\n",
    "    model.add(conv(256))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    \n",
    "    # 네 번째 Conv Block\n",
    "    model.add(conv(512))\n",
    "    model.add(conv(512))\n",
    "    model.add(conv(512))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    \n",
    "    # 다섯 번째 Conv Block\n",
    "    model.add(conv(512))\n",
    "    model.add(conv(512))\n",
    "    model.add(conv(512))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    \n",
    "    # Fully Connected Layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(4096, activation= tf.nn.relu))\n",
    "    model.add(keras.layers.Dense(512, activation= tf.nn.relu))\n",
    "    model.add(keras.layers.Dense(4, activation= tf.nn.softmax))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n",
    "def main():\n",
    "    \n",
    "    train_images, test_images, train_labels, test_labels = get_images_and_preprocessing(224)\n",
    "\n",
    "    print(train_images.shape)\n",
    "    print(type(train_images))\n",
    "    \n",
    "    \n",
    "    # 지시사항 2에서 설정한 모델을 불러옵니다.\n",
    "    model = VGG16(224)\n",
    "    \n",
    "    # 모델의 구조를 확인합니다.\n",
    "    model.summary()\n",
    "    \n",
    "    # 컴파일러를 설정합니다.\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "    model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    # fit 함수를 사용하여 모델을 학습합니다.\n",
    "    # 학습 수행 시 정보는 history에 저장합니다.\n",
    "    history = model.fit(train_images,train_labels, epochs=5, batch_size=256, validation_data=(test_images, test_labels), verbose = 2)\n",
    "    \n",
    "    # evaluate 함수를 사용하여 테스트 데이터의 결과값을 저장합니다.\n",
    "    loss, test_acc = model.evaluate(test_images,test_labels, verbose=2)\n",
    "    \n",
    "    print('\\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))\n",
    "    print('예측한 Test Data 클래스 : ',model.predict_classes(test_images))\n",
    "    \n",
    "    Visulaize([('VGGNet', history)], 'loss')\n",
    "     \n",
    "    Plotter(test_images, model)\n",
    "    \n",
    "    return test_acc\n",
    "\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도 : 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 224, 224, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "Model: \"model_59\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_145 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPadding2 (None, 230, 230, 3)  0           input_145[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1373 (Conv2D)            (None, 112, 112, 64) 9472        zero_padding2d_21[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_961 (BatchN (None, 112, 112, 64) 256         conv2d_1373[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_886 (Activation)     (None, 112, 112, 64) 0           batch_normalization_961[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_263 (MaxPooling2D (None, 55, 55, 64)   0           activation_886[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1374 (Conv2D)            (None, 55, 55, 64)   4160        max_pooling2d_263[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_962 (BatchN (None, 55, 55, 64)   256         conv2d_1374[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_887 (Activation)     (None, 55, 55, 64)   0           batch_normalization_962[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1375 (Conv2D)            (None, 55, 55, 64)   36928       activation_887[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_963 (BatchN (None, 55, 55, 64)   256         conv2d_1375[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_888 (Activation)     (None, 55, 55, 64)   0           batch_normalization_963[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1376 (Conv2D)            (None, 55, 55, 256)  16640       activation_888[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1377 (Conv2D)            (None, 55, 55, 256)  16640       max_pooling2d_263[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_964 (BatchN (None, 55, 55, 256)  1024        conv2d_1376[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_965 (BatchN (None, 55, 55, 256)  1024        conv2d_1377[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_288 (Add)                   (None, 55, 55, 256)  0           batch_normalization_964[0][0]    \n",
      "                                                                 batch_normalization_965[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_889 (Activation)     (None, 55, 55, 256)  0           add_288[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1378 (Conv2D)            (None, 55, 55, 64)   16448       activation_889[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_966 (BatchN (None, 55, 55, 64)   256         conv2d_1378[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_890 (Activation)     (None, 55, 55, 64)   0           batch_normalization_966[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1379 (Conv2D)            (None, 55, 55, 64)   36928       activation_890[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_967 (BatchN (None, 55, 55, 64)   256         conv2d_1379[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_891 (Activation)     (None, 55, 55, 64)   0           batch_normalization_967[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1380 (Conv2D)            (None, 55, 55, 256)  16640       activation_891[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_968 (BatchN (None, 55, 55, 256)  1024        conv2d_1380[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_289 (Add)                   (None, 55, 55, 256)  0           batch_normalization_968[0][0]    \n",
      "                                                                 activation_889[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_892 (Activation)     (None, 55, 55, 256)  0           add_289[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1381 (Conv2D)            (None, 55, 55, 64)   16448       activation_892[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_969 (BatchN (None, 55, 55, 64)   256         conv2d_1381[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_893 (Activation)     (None, 55, 55, 64)   0           batch_normalization_969[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1382 (Conv2D)            (None, 55, 55, 64)   36928       activation_893[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_970 (BatchN (None, 55, 55, 64)   256         conv2d_1382[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_894 (Activation)     (None, 55, 55, 64)   0           batch_normalization_970[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1383 (Conv2D)            (None, 55, 55, 256)  16640       activation_894[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_971 (BatchN (None, 55, 55, 256)  1024        conv2d_1383[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_290 (Add)                   (None, 55, 55, 256)  0           batch_normalization_971[0][0]    \n",
      "                                                                 activation_892[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_895 (Activation)     (None, 55, 55, 256)  0           add_290[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1384 (Conv2D)            (None, 28, 28, 128)  32896       activation_895[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_972 (BatchN (None, 28, 28, 128)  512         conv2d_1384[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_896 (Activation)     (None, 28, 28, 128)  0           batch_normalization_972[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1385 (Conv2D)            (None, 28, 28, 128)  147584      activation_896[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_973 (BatchN (None, 28, 28, 128)  512         conv2d_1385[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_897 (Activation)     (None, 28, 28, 128)  0           batch_normalization_973[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1386 (Conv2D)            (None, 28, 28, 512)  66048       activation_897[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1387 (Conv2D)            (None, 28, 28, 512)  131584      activation_895[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_974 (BatchN (None, 28, 28, 512)  2048        conv2d_1386[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_975 (BatchN (None, 28, 28, 512)  2048        conv2d_1387[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_291 (Add)                   (None, 28, 28, 512)  0           batch_normalization_974[0][0]    \n",
      "                                                                 batch_normalization_975[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_898 (Activation)     (None, 28, 28, 512)  0           add_291[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1388 (Conv2D)            (None, 28, 28, 128)  65664       activation_898[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_976 (BatchN (None, 28, 28, 128)  512         conv2d_1388[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_899 (Activation)     (None, 28, 28, 128)  0           batch_normalization_976[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1389 (Conv2D)            (None, 28, 28, 128)  147584      activation_899[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_977 (BatchN (None, 28, 28, 128)  512         conv2d_1389[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_900 (Activation)     (None, 28, 28, 128)  0           batch_normalization_977[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1390 (Conv2D)            (None, 28, 28, 512)  66048       activation_900[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_978 (BatchN (None, 28, 28, 512)  2048        conv2d_1390[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_292 (Add)                   (None, 28, 28, 512)  0           batch_normalization_978[0][0]    \n",
      "                                                                 activation_898[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_901 (Activation)     (None, 28, 28, 512)  0           add_292[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1391 (Conv2D)            (None, 28, 28, 128)  65664       activation_901[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_979 (BatchN (None, 28, 28, 128)  512         conv2d_1391[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_902 (Activation)     (None, 28, 28, 128)  0           batch_normalization_979[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1392 (Conv2D)            (None, 28, 28, 128)  147584      activation_902[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_980 (BatchN (None, 28, 28, 128)  512         conv2d_1392[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_903 (Activation)     (None, 28, 28, 128)  0           batch_normalization_980[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1393 (Conv2D)            (None, 28, 28, 512)  66048       activation_903[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_981 (BatchN (None, 28, 28, 512)  2048        conv2d_1393[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_293 (Add)                   (None, 28, 28, 512)  0           batch_normalization_981[0][0]    \n",
      "                                                                 activation_901[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_904 (Activation)     (None, 28, 28, 512)  0           add_293[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1394 (Conv2D)            (None, 28, 28, 128)  65664       activation_904[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_982 (BatchN (None, 28, 28, 128)  512         conv2d_1394[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_905 (Activation)     (None, 28, 28, 128)  0           batch_normalization_982[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1395 (Conv2D)            (None, 28, 28, 128)  147584      activation_905[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_983 (BatchN (None, 28, 28, 128)  512         conv2d_1395[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_906 (Activation)     (None, 28, 28, 128)  0           batch_normalization_983[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1396 (Conv2D)            (None, 28, 28, 512)  66048       activation_906[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_984 (BatchN (None, 28, 28, 512)  2048        conv2d_1396[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_294 (Add)                   (None, 28, 28, 512)  0           batch_normalization_984[0][0]    \n",
      "                                                                 activation_904[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_907 (Activation)     (None, 28, 28, 512)  0           add_294[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1397 (Conv2D)            (None, 14, 14, 256)  131328      activation_907[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_985 (BatchN (None, 14, 14, 256)  1024        conv2d_1397[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_908 (Activation)     (None, 14, 14, 256)  0           batch_normalization_985[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1398 (Conv2D)            (None, 14, 14, 256)  590080      activation_908[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_986 (BatchN (None, 14, 14, 256)  1024        conv2d_1398[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_909 (Activation)     (None, 14, 14, 256)  0           batch_normalization_986[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1399 (Conv2D)            (None, 14, 14, 1024) 263168      activation_909[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1400 (Conv2D)            (None, 14, 14, 1024) 525312      activation_907[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_987 (BatchN (None, 14, 14, 1024) 4096        conv2d_1399[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_988 (BatchN (None, 14, 14, 1024) 4096        conv2d_1400[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_295 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_987[0][0]    \n",
      "                                                                 batch_normalization_988[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_910 (Activation)     (None, 14, 14, 1024) 0           add_295[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1401 (Conv2D)            (None, 14, 14, 256)  262400      activation_910[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_989 (BatchN (None, 14, 14, 256)  1024        conv2d_1401[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_911 (Activation)     (None, 14, 14, 256)  0           batch_normalization_989[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1402 (Conv2D)            (None, 14, 14, 256)  590080      activation_911[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_990 (BatchN (None, 14, 14, 256)  1024        conv2d_1402[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_912 (Activation)     (None, 14, 14, 256)  0           batch_normalization_990[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1403 (Conv2D)            (None, 14, 14, 1024) 263168      activation_912[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_991 (BatchN (None, 14, 14, 1024) 4096        conv2d_1403[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_296 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_991[0][0]    \n",
      "                                                                 activation_910[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_913 (Activation)     (None, 14, 14, 1024) 0           add_296[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1404 (Conv2D)            (None, 14, 14, 256)  262400      activation_913[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_992 (BatchN (None, 14, 14, 256)  1024        conv2d_1404[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_914 (Activation)     (None, 14, 14, 256)  0           batch_normalization_992[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1405 (Conv2D)            (None, 14, 14, 256)  590080      activation_914[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_993 (BatchN (None, 14, 14, 256)  1024        conv2d_1405[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_915 (Activation)     (None, 14, 14, 256)  0           batch_normalization_993[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1406 (Conv2D)            (None, 14, 14, 1024) 263168      activation_915[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_994 (BatchN (None, 14, 14, 1024) 4096        conv2d_1406[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_297 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_994[0][0]    \n",
      "                                                                 activation_913[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_916 (Activation)     (None, 14, 14, 1024) 0           add_297[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1407 (Conv2D)            (None, 14, 14, 256)  262400      activation_916[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_995 (BatchN (None, 14, 14, 256)  1024        conv2d_1407[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_917 (Activation)     (None, 14, 14, 256)  0           batch_normalization_995[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1408 (Conv2D)            (None, 14, 14, 256)  590080      activation_917[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_996 (BatchN (None, 14, 14, 256)  1024        conv2d_1408[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_918 (Activation)     (None, 14, 14, 256)  0           batch_normalization_996[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1409 (Conv2D)            (None, 14, 14, 1024) 263168      activation_918[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_997 (BatchN (None, 14, 14, 1024) 4096        conv2d_1409[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_298 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_997[0][0]    \n",
      "                                                                 activation_916[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_919 (Activation)     (None, 14, 14, 1024) 0           add_298[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1410 (Conv2D)            (None, 14, 14, 256)  262400      activation_919[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_998 (BatchN (None, 14, 14, 256)  1024        conv2d_1410[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_920 (Activation)     (None, 14, 14, 256)  0           batch_normalization_998[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1411 (Conv2D)            (None, 14, 14, 256)  590080      activation_920[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_999 (BatchN (None, 14, 14, 256)  1024        conv2d_1411[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_921 (Activation)     (None, 14, 14, 256)  0           batch_normalization_999[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1412 (Conv2D)            (None, 14, 14, 1024) 263168      activation_921[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1000 (Batch (None, 14, 14, 1024) 4096        conv2d_1412[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_299 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1000[0][0]   \n",
      "                                                                 activation_919[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_922 (Activation)     (None, 14, 14, 1024) 0           add_299[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1413 (Conv2D)            (None, 14, 14, 256)  262400      activation_922[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1001 (Batch (None, 14, 14, 256)  1024        conv2d_1413[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_923 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1001[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1414 (Conv2D)            (None, 14, 14, 256)  590080      activation_923[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1002 (Batch (None, 14, 14, 256)  1024        conv2d_1414[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_924 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1002[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1415 (Conv2D)            (None, 14, 14, 1024) 263168      activation_924[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1003 (Batch (None, 14, 14, 1024) 4096        conv2d_1415[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_300 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1003[0][0]   \n",
      "                                                                 activation_922[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_925 (Activation)     (None, 14, 14, 1024) 0           add_300[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1416 (Conv2D)            (None, 7, 7, 512)    524800      activation_925[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1004 (Batch (None, 7, 7, 512)    2048        conv2d_1416[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_926 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1004[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1417 (Conv2D)            (None, 7, 7, 512)    2359808     activation_926[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1005 (Batch (None, 7, 7, 512)    2048        conv2d_1417[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_927 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1005[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1418 (Conv2D)            (None, 7, 7, 2048)   1050624     activation_927[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1419 (Conv2D)            (None, 7, 7, 2048)   2099200     activation_925[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1006 (Batch (None, 7, 7, 2048)   8192        conv2d_1418[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1007 (Batch (None, 7, 7, 2048)   8192        conv2d_1419[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_301 (Add)                   (None, 7, 7, 2048)   0           batch_normalization_1006[0][0]   \n",
      "                                                                 batch_normalization_1007[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_928 (Activation)     (None, 7, 7, 2048)   0           add_301[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1420 (Conv2D)            (None, 7, 7, 512)    1049088     activation_928[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1008 (Batch (None, 7, 7, 512)    2048        conv2d_1420[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_929 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1008[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1421 (Conv2D)            (None, 7, 7, 512)    2359808     activation_929[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1009 (Batch (None, 7, 7, 512)    2048        conv2d_1421[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_930 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1009[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1422 (Conv2D)            (None, 7, 7, 2048)   1050624     activation_930[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1010 (Batch (None, 7, 7, 2048)   8192        conv2d_1422[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_302 (Add)                   (None, 7, 7, 2048)   0           batch_normalization_1010[0][0]   \n",
      "                                                                 activation_928[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_931 (Activation)     (None, 7, 7, 2048)   0           add_302[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1423 (Conv2D)            (None, 7, 7, 512)    1049088     activation_931[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1011 (Batch (None, 7, 7, 512)    2048        conv2d_1423[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_932 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1011[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1424 (Conv2D)            (None, 7, 7, 512)    2359808     activation_932[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1012 (Batch (None, 7, 7, 512)    2048        conv2d_1424[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_933 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1012[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1425 (Conv2D)            (None, 7, 7, 2048)   1050624     activation_933[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1013 (Batch (None, 7, 7, 2048)   8192        conv2d_1425[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_303 (Add)                   (None, 7, 7, 2048)   0           batch_normalization_1013[0][0]   \n",
      "                                                                 activation_931[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_934 (Activation)     (None, 7, 7, 2048)   0           add_303[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 1, 1, 2048)   0           activation_934[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_168 (Flatten)           (None, 2048)         0           average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_418 (Dense)               (None, 4)            8196        flatten_168[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 23,595,908\n",
      "Trainable params: 23,542,788\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 11s - loss: 1.3356 - accuracy: 0.3929 - val_loss: 182846800.0000 - val_accuracy: 0.4000\n",
      "1/1 - 1s - loss: 182846800.0000 - accuracy: 0.4000\n",
      "\n",
      "Test Loss : 182846800.0000 | Test Accuracy : 0.4000000059604645\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters):\n",
    "    \n",
    "    filters1, filters2, filters3 = filters\n",
    "    \n",
    "    x = Conv2D(filters1, (1, 1))(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    '''\n",
    "    지시사항 1번\n",
    "    아래 내용을 채워 identity_block()을 완성하세요.\n",
    "    '''\n",
    "    # 입력(x) : input_tensor와 F(x) : x를 더해줍니다.\n",
    "    # TODO : add()와 Activation() 메서드를 사용해서 relu(F(x) + x) 의 형태로 만들어보세요. \n",
    "    x = add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def residual_block(input_tensor, kernel_size, filters, strides=(2, 2)):\n",
    "    filters1 , filters2 , filters3 = filters\n",
    "    \n",
    "    # 입력 Feature Map의 Size를 1/2로 줄이는 대신 Feature map의 Dimension을 2배로 늘려줍니다.\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides)(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    지시사항 2번\n",
    "    아래 내용을 채워 residual_block()을 완성하세요.\n",
    "    '''\n",
    "    # TODO : Projection Shortcut Connection을 구현해보세요.\n",
    "    # 1 x 1 Convolution 연산을 수행하여 Dimension을 2배로 증가시키고\n",
    "    # 입력 Feature map의 size를 1/2로 축소시켜보세요.\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides)(input_tensor)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    # F(x) : x와 Shortcut Connection : shortcut을 더해줍니다.\n",
    "    # TODO : add()와 Activation() 메서드를 사용해서 relu(F(x) + shortcut) 의 형태로 만들어보세요.\n",
    "    x = add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResNet50(img_size):\n",
    "    # 입력 이미지의 Shape을 정해줍니다.\n",
    "    shape = (img_size,img_size,3)\n",
    "    inputs = Input(shape)\n",
    "    \n",
    "    # 입력 영상의 크기를 줄이기 위한 Conv & Max-pooling\n",
    "    x = ZeroPadding2D((3, 3))(inputs)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    # 첫 번째 Residual Block (입력 영상 Size 2배 축소 / Dimension 2배 증가)\n",
    "    x = residual_block(x, 3, [64, 64, 256], strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256])\n",
    "    x = identity_block(x, 3, [64, 64, 256])\n",
    "    \n",
    "    \n",
    "    # 두 번째 Residual Block (입력 영상 Size 2배 축소 / Dimension 2배 증가)\n",
    "    x = residual_block(x, 3, [128, 128, 512])\n",
    "    x = identity_block(x, 3, [128, 128, 512])\n",
    "    x = identity_block(x, 3, [128, 128, 512])\n",
    "    x = identity_block(x, 3, [128, 128, 512])\n",
    "    \n",
    "    # 세 번째 Residual Block (입력 영상 Size 2배 축소 / Dimension 2배 증가)\n",
    "    x = residual_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    \n",
    "    # 네 번째 Residual Block (입력 영상 Size 2배 축소 / Dimension 2배 증가)\n",
    "    x = residual_block(x, 3, [512, 512, 2048])\n",
    "    x = identity_block(x, 3, [512, 512, 2048])\n",
    "    x = identity_block(x, 3, [512, 512, 2048])\n",
    "\n",
    "    # 마지막단에서 FC layer를 쓰지 않고 단순히 Averaging 합니다.\n",
    "    x = AveragePooling2D((7, 7))(x)\n",
    "    # x = GlobalAveragePooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    # 1000개의 Class 구분\n",
    "    x = Dense(4, activation='softmax')(x)\n",
    "    \n",
    "    # 모델 구성\n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "    \n",
    "\n",
    "def main():\n",
    "    \n",
    "    train_images, test_images, train_labels, test_labels = get_images_and_preprocessing(224)\n",
    "\n",
    "    print(train_images.shape)\n",
    "    print(type(train_images))\n",
    "    \n",
    "    \n",
    "    # 지시사항 2에서 설정한 모델을 불러옵니다.\n",
    "    model = ResNet50(224)\n",
    "    \n",
    "    # 모델의 구조를 확인합니다.\n",
    "    model.summary()\n",
    "    \n",
    "    # 컴파일러를 설정합니다.\n",
    "    optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "    model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    # fit 함수를 사용하여 모델을 학습합니다.\n",
    "    # 학습 수행 시 정보는 history에 저장합니다.\n",
    "    history = model.fit(train_images,train_labels, epochs=1, batch_size=512, validation_data=(test_images, test_labels), verbose = 2)\n",
    "    \n",
    "    # evaluate 함수를 사용하여 테스트 데이터의 결과값을 저장합니다.\n",
    "    loss, test_acc = model.evaluate(test_images,test_labels, verbose=2)\n",
    "    \n",
    "    print('\\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))\n",
    "#     print('예측한 Test Data 클래스 : ',model.predict_classes(test_images)[:10])\n",
    "    \n",
    "    Visulaize([('ResNet', history)], 'loss')\n",
    "     \n",
    "#     Plotter(test_images, model)\n",
    "    \n",
    "    return test_acc\n",
    "\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "빠름 : CNN, ResNet50     \n",
    "느림 : VGGNet   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

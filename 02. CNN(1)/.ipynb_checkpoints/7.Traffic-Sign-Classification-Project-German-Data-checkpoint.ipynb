{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. import & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from visual import *\n",
    "from plotter import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Input,  MaxPooling2D, GlobalMaxPooling2D, ZeroPadding2D, AveragePooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, add\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def load_images(path, names):\n",
    "    \n",
    "    images= [ PIL.Image.open(path + name) for name in names ]\n",
    "    #     print([i.size for i in images])\n",
    "    \n",
    "    return images\n",
    "\n",
    "def images2numpy(images, size):\n",
    "\n",
    "    output = [np.array(im.resize(size)) for im in images]\n",
    "    \n",
    "    output = np.array(output)\n",
    "    \n",
    "    return output\n",
    " \n",
    "def get_images_and_preprocessing(img_size):\n",
    "    \n",
    "    CSV_TRAIN_PATH = \"./German-Traffic-Sign/Train.csv\"\n",
    "    CSV_TEST_PATH = \"./German-Traffic-Sign/Test.csv\"\n",
    "    IMG_PATH = \"./German-Traffic-Sign/\"\n",
    "    IMG_SIZE = (img_size,img_size)\n",
    "\n",
    "    name_train_caption = load_data(CSV_TRAIN_PATH)\n",
    "    name_test_caption = load_data(CSV_TEST_PATH)\n",
    "    names_train = name_train_caption['Path']\n",
    "    names_test = name_test_caption['Path']\n",
    "    \n",
    "    images_train = load_images(IMG_PATH,names_train)\n",
    "    images_test = load_images(IMG_PATH,names_test)\n",
    "    np_train_images = images2numpy(images_train,IMG_SIZE)\n",
    "    np_test_images = images2numpy(images_test,IMG_SIZE)\n",
    "   \n",
    "    label_train_caption = load_data(CSV_TRAIN_PATH)\n",
    "    label_test_caption = load_data(CSV_TEST_PATH)\n",
    "    np_train_labels = label_train_caption['ClassId'].tolist()\n",
    "    np_test_labels = label_test_caption['ClassId'].tolist()\n",
    "\n",
    "    train_images = np_train_images / 255.\n",
    "    test_images = np_test_images / 255.\n",
    "    \n",
    "    train_labels = to_categorical(np_train_labels, 43)\n",
    "    test_labels = to_categorical(np_test_labels, 43)\n",
    "    \n",
    "    return train_images, test_images, train_labels, test_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28\n",
    "\n",
    "CSV_TRAIN_PATH = \"./German-Traffic-Sign/Train.csv\"\n",
    "CSV_TEST_PATH = \"./German-Traffic-Sign/Test.csv\"\n",
    "IMG_PATH = \"./German-Traffic-Sign/\"\n",
    "IMG_SIZE = (img_size,img_size)\n",
    "    \n",
    "label_train_caption = load_data(CSV_TRAIN_PATH)\n",
    "label_test_caption = load_data(CSV_TEST_PATH)\n",
    "np_labels_train = label_train_caption['ClassId'].tolist()\n",
    "np_labels_test = label_test_caption['ClassId'].tolist()\n",
    "\n",
    "# name_train_caption = load_data(CSV_TRAIN_PATH)\n",
    "# name_test_caption = load_data(CSV_TEST_PATH)\n",
    "# names_train = name_train_caption['Path']\n",
    "# names_test = name_test_caption['Path']\n",
    "\n",
    "# images_train = load_images(IMG_PATH,names_train)\n",
    "# images_test = load_images(IMG_PATH,names_test)\n",
    "# np_train_images = images2numpy(images_train,IMG_SIZE)\n",
    "# np_test_images = images2numpy(images_test,IMG_SIZE)\n",
    "\n",
    "\n",
    "my_set = set(np_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MLP(다층 퍼셉트론 모델)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도 : 0.85\n",
    "epoch = 50, batch_size = 256, image_size = 28, layer = 3 (relu, relu, softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 28, 28, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 2352)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1204736   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 1,347,115\n",
      "Trainable params: 1,347,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "154/154 - 2s - loss: 2.1806 - accuracy: 0.4569 - val_loss: 1.4877 - val_accuracy: 0.6171\n",
      "Epoch 2/50\n",
      "154/154 - 2s - loss: 0.9744 - accuracy: 0.7592 - val_loss: 1.0702 - val_accuracy: 0.7251\n",
      "Epoch 3/50\n",
      "154/154 - 1s - loss: 0.6213 - accuracy: 0.8485 - val_loss: 0.8947 - val_accuracy: 0.7838\n",
      "Epoch 4/50\n",
      "154/154 - 1s - loss: 0.4754 - accuracy: 0.8860 - val_loss: 0.9033 - val_accuracy: 0.7836\n",
      "Epoch 5/50\n",
      "154/154 - 1s - loss: 0.4069 - accuracy: 0.8972 - val_loss: 0.8111 - val_accuracy: 0.8059\n",
      "Epoch 6/50\n",
      "154/154 - 2s - loss: 0.3465 - accuracy: 0.9155 - val_loss: 0.9355 - val_accuracy: 0.7949\n",
      "Epoch 7/50\n",
      "154/154 - 2s - loss: 0.3042 - accuracy: 0.9237 - val_loss: 0.7849 - val_accuracy: 0.8288\n",
      "Epoch 8/50\n",
      "154/154 - 2s - loss: 0.2625 - accuracy: 0.9381 - val_loss: 0.7785 - val_accuracy: 0.8396\n",
      "Epoch 9/50\n",
      "154/154 - 2s - loss: 0.2700 - accuracy: 0.9322 - val_loss: 0.8462 - val_accuracy: 0.8112\n",
      "Epoch 10/50\n",
      "154/154 - 2s - loss: 0.2318 - accuracy: 0.9440 - val_loss: 0.8853 - val_accuracy: 0.8274\n",
      "Epoch 11/50\n",
      "154/154 - 2s - loss: 0.2461 - accuracy: 0.9382 - val_loss: 0.8580 - val_accuracy: 0.8306\n",
      "Epoch 12/50\n",
      "154/154 - 2s - loss: 0.1875 - accuracy: 0.9549 - val_loss: 0.8665 - val_accuracy: 0.8344\n",
      "Epoch 13/50\n",
      "154/154 - 2s - loss: 0.1859 - accuracy: 0.9531 - val_loss: 0.9786 - val_accuracy: 0.8294\n",
      "Epoch 14/50\n",
      "154/154 - 2s - loss: 0.1676 - accuracy: 0.9602 - val_loss: 0.9329 - val_accuracy: 0.8171\n",
      "Epoch 15/50\n",
      "154/154 - 2s - loss: 0.1805 - accuracy: 0.9548 - val_loss: 0.8392 - val_accuracy: 0.8475\n",
      "Epoch 16/50\n",
      "154/154 - 2s - loss: 0.1337 - accuracy: 0.9699 - val_loss: 0.7893 - val_accuracy: 0.8574\n",
      "Epoch 17/50\n",
      "154/154 - 2s - loss: 0.1330 - accuracy: 0.9679 - val_loss: 0.9766 - val_accuracy: 0.8317\n",
      "Epoch 18/50\n",
      "154/154 - 2s - loss: 0.1506 - accuracy: 0.9616 - val_loss: 0.8777 - val_accuracy: 0.8334\n",
      "Epoch 19/50\n",
      "154/154 - 2s - loss: 0.1482 - accuracy: 0.9607 - val_loss: 0.7727 - val_accuracy: 0.8660\n",
      "Epoch 20/50\n",
      "154/154 - 2s - loss: 0.1143 - accuracy: 0.9714 - val_loss: 1.0223 - val_accuracy: 0.8422\n",
      "Epoch 21/50\n",
      "154/154 - 2s - loss: 0.0968 - accuracy: 0.9768 - val_loss: 0.8708 - val_accuracy: 0.8491\n",
      "Epoch 22/50\n",
      "154/154 - 2s - loss: 0.1044 - accuracy: 0.9732 - val_loss: 0.9270 - val_accuracy: 0.8384\n",
      "Epoch 23/50\n",
      "154/154 - 2s - loss: 0.1357 - accuracy: 0.9642 - val_loss: 1.1857 - val_accuracy: 0.8154\n",
      "Epoch 24/50\n",
      "154/154 - 2s - loss: 0.0947 - accuracy: 0.9763 - val_loss: 0.8870 - val_accuracy: 0.8490\n",
      "Epoch 25/50\n",
      "154/154 - 2s - loss: 0.0954 - accuracy: 0.9750 - val_loss: 1.0120 - val_accuracy: 0.8371\n",
      "Epoch 26/50\n",
      "154/154 - 2s - loss: 0.0895 - accuracy: 0.9768 - val_loss: 0.8375 - val_accuracy: 0.8665\n",
      "Epoch 27/50\n",
      "154/154 - 2s - loss: 0.0846 - accuracy: 0.9778 - val_loss: 0.9365 - val_accuracy: 0.8534\n",
      "Epoch 28/50\n",
      "154/154 - 2s - loss: 0.0790 - accuracy: 0.9799 - val_loss: 0.9350 - val_accuracy: 0.8359\n",
      "Epoch 29/50\n",
      "154/154 - 2s - loss: 0.0725 - accuracy: 0.9808 - val_loss: 0.9223 - val_accuracy: 0.8588\n",
      "Epoch 30/50\n",
      "154/154 - 2s - loss: 0.0983 - accuracy: 0.9730 - val_loss: 0.8431 - val_accuracy: 0.8671\n",
      "Epoch 31/50\n",
      "154/154 - 2s - loss: 0.0729 - accuracy: 0.9799 - val_loss: 1.0128 - val_accuracy: 0.8418\n",
      "Epoch 32/50\n",
      "154/154 - 2s - loss: 0.0670 - accuracy: 0.9826 - val_loss: 1.0493 - val_accuracy: 0.8468\n",
      "Epoch 33/50\n",
      "154/154 - 2s - loss: 0.0558 - accuracy: 0.9857 - val_loss: 0.8362 - val_accuracy: 0.8772\n",
      "Epoch 34/50\n",
      "154/154 - 2s - loss: 0.0927 - accuracy: 0.9734 - val_loss: 1.1061 - val_accuracy: 0.8407\n",
      "Epoch 35/50\n",
      "154/154 - 2s - loss: 0.0657 - accuracy: 0.9812 - val_loss: 0.9843 - val_accuracy: 0.8591\n",
      "Epoch 36/50\n",
      "154/154 - 2s - loss: 0.0530 - accuracy: 0.9855 - val_loss: 1.0395 - val_accuracy: 0.8459\n",
      "Epoch 37/50\n",
      "154/154 - 2s - loss: 0.0603 - accuracy: 0.9836 - val_loss: 0.9643 - val_accuracy: 0.8622\n",
      "Epoch 38/50\n",
      "154/154 - 2s - loss: 0.0563 - accuracy: 0.9840 - val_loss: 0.9020 - val_accuracy: 0.8664\n",
      "Epoch 39/50\n",
      "154/154 - 2s - loss: 0.0569 - accuracy: 0.9846 - val_loss: 1.1307 - val_accuracy: 0.8496\n",
      "Epoch 40/50\n",
      "154/154 - 2s - loss: 0.0485 - accuracy: 0.9862 - val_loss: 0.9749 - val_accuracy: 0.8677\n",
      "Epoch 41/50\n",
      "154/154 - 2s - loss: 0.0337 - accuracy: 0.9913 - val_loss: 1.0953 - val_accuracy: 0.8563\n",
      "Epoch 42/50\n",
      "154/154 - 2s - loss: 0.0793 - accuracy: 0.9765 - val_loss: 0.9573 - val_accuracy: 0.8506\n",
      "Epoch 43/50\n",
      "154/154 - 2s - loss: 0.0842 - accuracy: 0.9755 - val_loss: 1.2839 - val_accuracy: 0.8308\n",
      "Epoch 44/50\n",
      "154/154 - 2s - loss: 0.0516 - accuracy: 0.9862 - val_loss: 1.0418 - val_accuracy: 0.8688\n",
      "Epoch 45/50\n",
      "154/154 - 2s - loss: 0.0279 - accuracy: 0.9926 - val_loss: 1.1963 - val_accuracy: 0.8522\n",
      "Epoch 46/50\n",
      "154/154 - 2s - loss: 0.0464 - accuracy: 0.9874 - val_loss: 1.1243 - val_accuracy: 0.8553\n",
      "Epoch 47/50\n",
      "154/154 - 2s - loss: 0.1042 - accuracy: 0.9711 - val_loss: 1.2005 - val_accuracy: 0.8538\n",
      "Epoch 48/50\n",
      "154/154 - 2s - loss: 0.0490 - accuracy: 0.9863 - val_loss: 1.0827 - val_accuracy: 0.8656\n",
      "Epoch 49/50\n",
      "154/154 - 2s - loss: 0.0328 - accuracy: 0.9911 - val_loss: 1.1699 - val_accuracy: 0.8458\n",
      "Epoch 50/50\n",
      "154/154 - 2s - loss: 0.0405 - accuracy: 0.9881 - val_loss: 1.0680 - val_accuracy: 0.8572\n",
      "395/395 [==============================] - 1s 2ms/step - loss: 1.0680 - accuracy: 0.8572\n",
      "\n",
      "Test Loss : 1.0680 | Test Accuracy : 0.8571654558181763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/LG/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측한 Test Data 클래스 :  [16  1 38 ... 15  7 10]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABCSklEQVR4nO3dd3hUZdr48e8zJZn0RhJSKAm9VykCAoqKDXRfLNhlXVfXuuqu7r6ubd33t+6uXVfs6OpiQUXFivQOobcAgUAIpPc+yczz+2OGmMAkmZQhmeT+XNdcmZw558wzBzL3edr9KK01Qgghui5DexdACCFE+5JAIIQQXZwEAiGE6OIkEAghRBcngUAIIbo4U3sXoLm6deume/fu3d7FEEIIr7J169ZcrXWkq9e8LhD07t2bpKSk9i6GEEJ4FaXUsYZek6YhIYTo4iQQCCFEFyeBQAghujiv6yMQQnRu1dXVpKenU1lZ2d5F8UoWi4X4+HjMZrPbx0ggEEJ0KOnp6QQFBdG7d2+UUu1dHK+itSYvL4/09HQSEhLcPk6ahoQQHUplZSURERESBFpAKUVERESza1MSCIQQHY4EgZZrybXzukCQXVLV3kUQQohOxfsCQbF0IAkhPEspxU033VT7e01NDZGRkVx++eUALFiwgHvuucetc+3evZuRI0cycuRIwsPDSUhIYOTIkcyYMcPt8ixevJh9+/Y170M0g9d1FmugstqGxWxs76IIITqpgIAA9uzZQ0VFBX5+fixdupS4uLgWnWvYsGHs2LEDgFtvvZXLL7+cOXPmNOscixcv5vLLL2fw4MEtKkNTvK5GAFBSWdPeRRBCdHKXXHIJ3377LQALFy5k7ty5Lve79dZbufPOO5kyZQr9+/dnyZIlbp3/p59+YuLEiYwePZqrr76a0tJSAB599FEGDx7M8OHDefjhh1m/fj1ff/01f/jDHxg5ciSHDx9umw9Yh9fVCACKK6uJDPJt72IIIc6Ca9/YcMa2y4fHcNPE3lRYbdz63uYzXp8zJp6rx/Ygv8zKXR9urffaJ7+d6Nb7XnfddTz99NNcfvnl7Nq1i3nz5rFmzRqX+x49epRVq1Zx+PBhpk+fTkpKChaLpcFz5+bm8swzz/Dzzz8TEBDAs88+y/PPP88999zDl19+SXJyMkopCgsLCQ0NZdasWS2qSbjLKwOB1AiEEJ42fPhwjh49ysKFC7n00ksb3feaa67BYDDQr18/EhMTSU5OZuTIkQ3uv3HjRvbt28ekSZMAsFqtTJw4keDgYCwWC7fffjuXXXZZbZ+Ep3llICiuqG7vIgghzpLG7uD9fIyNvh4e4ON2DcCVWbNm8fDDD7Ny5Ury8vIa3O/0IZtNDeHUWnPhhReycOHCM17bvHkzy5Yt4+OPP+bVV19l+fLlLSt8M3hlH0FxpQQCIYTnzZs3j8cff5xhw4Y1ut9nn32G3W7n8OHDHDlyhAEDBjS6/4QJE1i3bh0pKSkAlJeXc/DgQUpLSykqKuLSSy/lxRdfrO1kDgoKoqSkpE0+kyteWiOQpiEhhOfFx8dz//33N7nfgAEDmDp1KllZWcyfP7/R/gGAyMhIFixYwNy5c6mqcsyNeuaZZwgKCmL27NlUVlaiteaFF14AHP0Vv/nNb3j55ZdZtGgRffr0af2Hq0Nprdv0hJ7mG9NPv/TxD9w5tW0vhBCiY9i/fz+DBg1q72K4raVDQj3J1TVUSm3VWo91tb9XNg2VSNOQEEK0Ga9rGjIalDQNCSE6jAULFrR3EVrN62oERqWks1gIIdqQ9wUCg5Lho0II0Ya8MhDIhDIhhGg7HgsESqkeSqkVSqn9Sqm9SqkzxmAph5eVUilKqV1KqdFNndcgTUNCCNGmPFkjqAEe0loPAiYAdyulTk+ddwnQz/m4A3i9qZNKZ7EQwtM6Uhrqr7/+mr///e/N/xDN4LFRQ1rrDCDD+bxEKbUfiAPqJtWeDXygHZMZNiqlQpVSMc5jXTIapEYghPCss52GuqamBpPJ9dfxrFmzmDVrVove211npY9AKdUbGAVsOu2lOOB4nd/TndtOP/4OpVSSUiqpsqKccquNapvdY+UVQghPp6GeNm0af/7zn5k6dSovvfQS33zzDePHj2fUqFHMmDGDrKwsoH7t49Zbb+W+++7j3HPPJTExkUWLFrXBJz0L8wiUUoHA58ADWuvi0192ccgZU5211m8CbwIkDBymNVBaWUNYgE9bF1cI0YE89c1e9p08/WujdQbHBvPEFUOa3M+TaahPKSwsZNWqVQAUFBSwceNGlFK8/fbb/OMf/+C5554745iMjAzWrl1LcnIys2bNapMZzR4NBEopM44g8JHW+gsXu6QDPer8Hg+cbOycBoPChiPxnAQCIYSneDIN9SnXXntt7fP09HSuvfZaMjIysFqtJCQkuDzmyiuvxGAwMHjw4NpaQ2t5LBAoRx7Wd4D9WuvnG9jta+AepdTHwHigqLH+AXD0EdiQxHNCdAXu3Ll7kqfSUJ8SEBBQ+/zee+/lwQcfZNasWaxcuZInn3zS5TG+vr8sytVWueI8WSOYBNwE7FZK7XBu+zPQE0BrPR/4DrgUSAHKgduaOqnReYGlw1gI4Wnz5s0jJCSEYcOGsXLlygb3++yzz7jllltITU11Kw21K0VFRbUd0u+//35Li9winhw1tBbXfQB199HA3c05r9HgDAQyu1gI4WGeSkPtypNPPsnVV19NXFwcEyZMIDU1tSVFbhGvS0M9YtRoXXTxX/nH/wznmnN6NH2AEMKrSBrq1uv0aagNBmkaEkKItuR9aaiVQilpGhJCdAyShrqdBPmaKJbEc0J0Wt7WZN2RtOTaeWUgCPYzS41AiE7KYrGQl5cnwaAFtNbk5eU1u7Pa65qGAIItZqkRCNFJxcfHk56eTk5OTnsXxStZLBbi4+ObdYxXBoIgi0k6i4XopMxmc4OzaoVnSNOQEEJ0cd4ZCCxmWaVMCCHaiHcGAj+T1AiEEKKNeGUgCLKYKbXWYLfLqAIhhGgtrwwEwRYTWkNJlTQPCSFEa3lnIPAzAzK7WAgh2oJ3BgKLMxDIEFIhhGg17wwEfo7pDzJySAghWs87A4FFmoaEEKKteHcgkBqBEEK0mncGAmfTkNQIhBCi9bwyEAT6OgOBdBYLIUSreWUgMBkNBPqapLNYCCHagFcGAnBmIJWmISGEaDWvDQSONQkkEAghRGt5byDwM1FcIU1DQgjRWt4bCKRGIIQQbcJ7A4GfrEkghBBtwWsDgSxXKYQQbcNrA0GwxbFcpdayJoEQQrSG9wYCPxN2DWVWW3sXRQghvJr3BgJJPCeEEG3CewOBc3Ea6TAWQojW8dpAEGSRfENCCNEWvDYQSNOQEEK0De8NBH6yXKUQQrQF7w0EFlmuUggh2oLXBoIgaRoSQog24bWBwMdkwGI2yHKVQgjRSl4bCOCX2cVCCCFazmOBQCn1rlIqWym1p4HXpymlipRSO5yPx5v7HsF+koFUCCFay+TBcy8AXgU+aGSfNVrry1v6BsEWWa5SCCFay2M1Aq31aiDfU+cHZ41AmoaEEKJV2ruPYKJSaqdS6nul1JCGdlJK3aGUSlJKJWVk59ZuD7KYpbNYCCFaqT0DwTagl9Z6BPAKsLihHbXWb2qtx2qtx+ZWmykoswKOpiGpEQghROu0WyDQWhdrrUudz78DzEqpbu4cm5xZAvzSWSxrEgghRMu1WyBQSnVXSinn83HOsuS5c2xyZjHgGD5abdNU1dg9Vk4hhOjsPDZqSCm1EJgGdFNKpQNPAGYArfV8YA5wl1KqBqgArtNu3NobDYoDtTUCZwbSimosZqMHPoUQQnR+HgsEWuu5Tbz+Ko7hpc1iMRnZ7wwEtWkmKquJCra0oJRCCCHae9RQs0UF+/LIzAHAL4nniipk5JAQQrSU1wWCQF8T5/Zx9ClLKmohhGg9T84s9gitYXlyFj3DA2oXp5HZxUII0XJeVyPQwK/fT+KbnSdrm4ZkLoEQQrSc1wUCg4KEiAAOZJZI05AQQrQBrwsEAAO6B5GcWYyvyYCP0UCxdBYLIUSLeWUgGNg9mGP55ZRbbQT7maRGIIQQreCVgWBA9yC0hoNZJQRbzNJZLIQQreB1o4YAzu0bwU+/P4+EbgEESeI5IYRoFa8MBMEWc+3QUVmlTAghWscrAwHA0n1ZpBeUE2wxc7Kwor2LI4QQXssr+wjAMans5WWHCJLlKoUQolW8NhAM7B5MQXk1JqOSpiEhhEdV2+yUdOLvGS8OBEEAlFttVFbbqaqxtXOJhBCd1UcbjzHx/y3HZu+ci2B5cSAIBn7JMyTNQ0IIT+kW5EtpVQ1bjxW0d1E8wmsDQYi/mZgQCxVWRwCQIaRCCE+w2zVT+0diNiqW7sts7+J4hNcGAoBlD01l3uQEQGoEQgjPWH84j6n/XEmwxczSfVmdco10rw4E/j6m2vkE0mEshPCErccKKCi38uspCRzNK+dwTml7F6nNeXUgSM4s5oWlBwEk8ZwQwiOSjuUzIDqIq0bFMbJHaKdcEdFrJ5Sdsu5wHiA1AiFE27PZNTvSCpk1MpaYED8W3z2pvYvkEV5dI0jsFojJ+Qmks1gI0dYOZZdQUlXDmF5htdvKqmoot3quVlBaVcPHm9OosJ69IfFeHQh8TAb6RAaikM5i0TqdebKQaDl/s4nfTElgfGIEAMfzyxn116V8s/Ok2+fYcjTf7cBRbq3htvc28+gXu3nupwMtKnNLuBUIlFIBSimD83l/pdQspZTZs0Vzz6CYYFDSNCRabtORPIY9+RPrUnLbuyiig+kZ4c//XjaYuFA/AOLD/IgM9GXpvqwmj9Vak1daxc3vbObmdzY3ebOhteZ3H21j67ECxvQK4911qexOL2qTz9EUd2sEqwGLUioOWAbcBizwVKGaY2SPUMwGAwXl1vYuivBSsc4/cnf+uEXXsju9CGuNvfZ3pRQXDo5mzaHcRu/yrTV2rnh1LasP5fCvq0ew43ghN76zmaLyhoOBUop5kxJ44dqRvHvrOUzpF4mhGW02y5OzePHngy0a3uru2yitdTnwK+AVrfVVwOBmv5sH3Dopgf7dAymrkhQTomV6hPszokcoe0+enbsv4R1ySqq44tW1LFifWm/7hYOjqaqxs/ZQwzXIxdtPsOdEMaF+Plw2PIbXbxzD/pPFzH1rI/ll9W9aq2psrD6YA8B5/SOZPTKOED8z788bx5DYELfKuuVoPnf+Zxsv/nyIDzYca+YnbUYgUEpNBG4AvnVu6zAjjoItZuksFi2SXVLJfzYcZUB0IDuOF57VDjrRsZ1KJ1G3oxhgXEI4QRZTgzVIm13z+qrDDIkNZtqASMARPN68eQyHc0pZuDmtdl9rjZ27P9rOre9tdjk/oaiimse/2sPx/PJGy/rl9hPEh/kxpV83/vbdfvadLG7WZ3X3y/wB4E/Al1rrvUqpRGBFs97Jgw5mlXTaZFDCs1YkZ/OXr/by6CUDqbZptqUVMKlvt/YulugAtqUV4GM0MDSu/l252Wjgn3NG0CcywOVx3+7OIDW3jNdvGI1Sqnb7tAFRfHPvZPpGBgJQY7Nz/8fb+Xl/Fk/PHkIf5/a6SqtqWLQ1nbT8ct679Zx656vrmdlDyS+3ooCr528gvaCcwbHBbn9WtwKB1noVsArA2Wmcq7W+z+138TCF44IJ0VwrD+QQE2Lhxgm96BcVyIgeoe1dJOEGu12zPDmbyf26YTEbPfIeW48VMCw+BF/TmeefObS7y2O01vx7RQp9owK5eMiZ+/SPdmRNPp5fzpR/OO6lH7tsEDdP7O3yfHGhfjx00QD+umQfS3ZlcMWI2NrXrDV2nvxmL3dN7UOPcH+6BfoC8NPvz8NkbN6AUHdHDf1XKRWslAoA9gEHlFJ/aNY7eVBkkIVqm8YutQLRDNU2O2sO5TJtQCSBviYuGBRNoG+HafEUjdiWVsDtHyTxwx7PJIGrqrGxO72Isac1C9W1bH8WS3bVH0aqlOKvVw7lqVlDMBhc370DFJRbiQ/z48+XDuT2KYmNluXWc3szPD6Ep77ZV9vZrLXmscW7+e+mNLal1c+IajIa0Frz301pfLsro6mPCrjfRzBYa10MXAl8B/QEbnLzWI+LDbUAcDSvrJ1LIrxJ0tECSqtqmDYgCoC0vHJeW5Ei/QRe4Ps9mfgYDfQI9+OrHSfa/PxGpfjg1+O45pweDe6zYP1Rnv/p4Bnbz+kd3mTz4vD4UNY+cj53nNen6bIYFP931TAKyq38yzm3YP6qI3yalM595/dl9si4M46x2TWLth7n0c93Ndm/AO4HArNz3sCVwFda62qgw9x+94pwtNXtOF7YvgURXmV/RjE+JkPtH+3hnFL++eMBtqd1zpzzbaXaZuc/G456dHZtY7TW/LAnk8n9uvHRxjQe/Xz3GSNxGpKaW8a8BVs4mtv4TaPJaGBCYoTLdvtTLhwczZHcMlKyHZ2861JyeWzx7kaHiLbU0LgQnv2f4fx2aiLf7c7g2R+SmTUilt9f2L/B8r903ShQcO/C7VTb7C73O8XdQPAGcBQIAFYrpXoBzeuW9qC+UY5AYGigI0UIV+ZNTiDpsRm1zUFje4dhULDxSF47l6zjenX5IS58fhV/+WovryxPaZcy7D5RxInCCmYO7c5d0/pQUW3jvXWpTR6nteZPX+xieXI2f/8+udF9v9ye3uT/gxmDogH4eb9j9NBLyw7x875sLD6eSdgwZ0w8caF+vLs2ldE9Q/nHnOENdh6DY1j0s/8znB3HC3nORc2lLrdKrLV+WWsdp7W+VDscA6Y361N4ULdAR9NQ36iGo7cQrpxKYw4QZDEzNC6Ejan57Viijm3JrgxiQvyYMyaet1Yf4VBWyVkvw+qDOZgMiosGR9MvOoiLh0SzYP3RJmfufrs7g41H8hkWF8IPezPPaFs/RWvN377dz6dJxxs9X2yoH0Nig1m6L4stR/PZnJrPHecluuxcbitKKd6fN463bznHrU7yS4fFMHdcT95YfbjR/dztLA5RSj2vlEpyPp7DUTvoEIIsjju6Q1ml0r4r3LJoazq3vHvmtP8JiRHsSCukslr+H50uu7iS5MwSzusfyZ8uGUiAr4m/fLXnrC/Ucvf0vvz0+/MI9fep/b2ksoYPN6Y1etyMQdH89cqhLLxjAr+b1ofeEa6/wtLyy8kttZ4xf8CVCwdHk11Syb9+PEBEgA9zx/Vs/gdqpgBfE+EBPm7v//jlg/nPvPGN7uNuHeZdoAS4xvkoBt5zuyQeduqu7vef7vBIx5HofH7cm0lKdukZo4QmJIaDorbdtzNbl5LbrFE3a5wzaaf060ZEoC9/nDmAjUfyWXyW/+aUUiTWabsfHh/KxUOisdkbbgevsdmxmI3cNKEXgb4m/jhzYINfpg1NJHPlrml9eO360WxKzefXUxLw8/FcbaCl/HyMTO7XeOe1u4Ggj9b6Ca31EefjKaDxMU9nUbCf4485JsTCgvVHO+VScqLtVNXYWJeSy/SBkWe0sU7uG8muJy46YxJRZ1FcWc3JwgoAjuSUcv/HTXcknrL6UA7dAn0YHOOYqDT3nJ7MGRNPz3D/Jo9dkZzNI4t2UdjKnGBvrznCn7/cfcZQ8fk3juGe8/u5PGbrsXymP7eSA5klp20v4Pef7DhjMmrSsQKCfE30jwpqsjy+JiNh/j7cOKEnN03o1cxP03G4GwgqlFKTT/2ilJoEVDR2gFLqXaVUtlJqTwOvK6XUy0qpFKXULqXUaPeLXV+wn6NGMLpnGMmZJWyWNl7RiKSjBZRbbUzrH3XGaz4mg8cmKLWnovJqXlh6kMl/X84TX+8FoHuInyNnjptZV/tHB3H9uJ614+MNBsW/rh7BmF7hDR5jrbHzf9/t57YFW/gk6XirVxL8NOk4h7NLzxijr5RCa836lNx6SeKqbXb+98s92Gya+DC/esdkFVfy5fYTfLEtvd725IxiRvUKa3QeQF09wv155sphBFk6RELmFnE3ENwJvKaUOqqUOgq8Cvy2iWMWADMbef0SoJ/zcQfwuptlOUOgjwmloFeEPyF+5hYlXRLeQ2tN0tH8Ftf8Vh7Ixsdo4Ny+ES5fX5GczZzX1zfZT1BVYyOvtKpFZThbSiqr+eePyUx6djkvLTvExD4R3H+B4875vP7dCLaY+GaHe7n1757elwcvGuDyPZ74ag+70gvrbT+eX841b2zgzdVHuGlCL/Y8dTE9I/zRWrdo6GlKdikHs0q5pIFZvZtS87n+7U31moffXZtKcmYJT84aQsBpzYCXDO3OiB6hPL/0YL1/60V3nstL145sdvm8mbujhnZqrUcAw4HhWutRwPlNHLMaaOzWfDbwgXMU0kYgVCkV42a56zEYFIG+JsqtNq49pwfLk7NlfYJO7Of92cyZv4EVB7JbdHxiZCA3TuiFv4/rWcR2rUk6VsD2tMJGz/PwZ7u48IXV7Tae3h3PLz3IaysOM3VAJN/fP4U3bhpb2+zlazJy6bAYftyb2eQgi4yiinp32nVp4Ls9mTy2eE+9Zpa//5DM4exS/n3DaP565dDa/pinl+xj7psbm/03+sMexyzZmUNdf02MTwhnUEwwr686jM2uSS8o58WfDzFjUDQXuUj3oJTi0ZkDySiq5IMNR2u3GwyKsGZ0xnYGzRrwqrUuds4wBniwle8dB9Qdn5Xu3NYiwRYzxZXV3HFeIqv/OL3esEDReSQdzSezqILoYF9eWpbSolrB3HE9efyKhrOoj+0d3uR8gnUpuXyz8yT5ZVa+3N5xByg8dtlgfnhgCq9dP9qxiNNpZo2IpcxqY8ORxpuHfv/JDq57c4PL14ItZh67bBC70ot4b11qbS3pqVlD+Pa+KVw6rP4X96Q+3diXUezWYi11fbc7k9E9Q+keYnH5ulKKu6f34UhOGT/uzazN8vnkrIb/rSf2iWDagEheW3GYovJqPtp0jL8sPvsjodpba2Y+tHb2lqvjXV59pdQdp4au5uTkuDxZsJ+ZksoaugX6EhnkSL7U1f4x3WW3t6xq3hH8d3Mazy09yD3n92Pn8cLakSzuSi8op6yJBIUhfmaGxIY0Ggi2HSugV4Q/g2KC+WD9sQ75f01rjdGgGNi94SyU4xMj+OGBKZw/MLrBfcqqath6rIBzEhruC5g1IpZJfSN45tv93PXhNrTWdAv0pWfEmR3JMwZH89r1o9lzosjlEF5Xamx2xvQK49pGUj4AXDI0hsRuAby2IoWHLhzA4rsnER/WeGf2IzMHcv8F/bD4GPh+dyZbjxU0OlGrM2pNIGjt//x0oO6/ajzgsrFSa/2m1nqs1npsZGSky5MFW0wUOdckyCut4pr5G876sDZv8egXuxjz15+Zv+qw2yNGWiqvtIorX1vXJh34Nrtm5YEcpvWP5NqxPYgNsfDSskPN+hJ+4qu9zH5tXZP7jU8IZ/vxhucT3HtBP767bwrPXDmEV64f1eG+OMqtNVzw3Kom19ZtKlCAo2ZUbdNM7ef6bw8cd+PPXDmMiYkR3HFeYpPX46Ih3Xn1+lHsTC/ijg+2NvlvaDIa+OuVQ7n2nMbH6RsNijun9SG7pIqTRRUM6N70yJ9BMcHMm5yAUSm2pxUwtnfTw0Y7m0YDgVKqRClV7OJRAsQ2dqwbvgZudo4emgAUaa3dS5XnQlyoH0dyytBaE+bvQ25ZFQvWS6fx6Zbtz+LTpHSig335+/fJXPbyGo64WBCjrYT5+2AyKG5/fwu5rexY3XG8kPwyK+cPisbHZOCuaX04lldOVrF7562strHucC6T+rjuJK5r6oBIpvaPrL25OCW7pJKdzpxWAb4mxvQKr00t3JF8se0ER3LLGmxGqausqoYHP2l4Ds7qgzn4mY2MaeILMqFbAAvvmMCMwQ3XLuqaOTSGV+aO4jfnJTQZOPZnFLudXfiqUXGs+eP0JmsCp3v2h2TKrDa35g90No0GAq11kNY62MUjSGvdaL5epdRCYAMwQCmVrpT6tVLqTqXUnc5dvgOOACnAW8DvWvNBRvQIJbe0ioyiSgwGxS0Te7PzeKEkojtN9xALs0bE8tPvp/LWzWMJtpiJCnZ8WXiiecNgUDw9eyhVNXaXY7abY9n+LIwGxdT+jjvTa87pwZo/Tnfryw5gc2o+ldV2pg08c9jo6ab0i+Stm8cSHVz/3P/vu2SueWNDvSRnaXnl3Ltwu1tZHs8Gu13z3rpUhseHNJpG+RR/HyNb0wr4LCnd5eurD+UyITHcI6kTLh0WU9ss9eX2dJcpK04WVnDJS2t41418QuBYOKYlQ4CP5Tn+/SQQtCGt9VytdYzW2qy1jtdav6O1nq+1nu98XWut79Za99FaD9NaJ7Xm/U4tKHJqCNuvRscR4GPkg/VHW/U5GtKcTq6OZEhsCC/PHYWPycCFg6NZdNe5BPqaqKqxcfX8DXyyJa3N1nX4ascJrn9rI91DLDw5awhrDuXy7xUtT1SWXlDBuN7hhDjnjfiajPj5GKmx2ckuqWzy+BUHsvE1GZiY2HSN4JS6NYLNqfl8uf0Ev5mSWG9Wqsmo+G53Bh9ucr8GuudEEVuO5rM9rYA9J4pIzixus0Cy+lAOh3PKmDep6TttcDTrzBoRy/rDuWdcR601z/7PcO45v2+blK0hFVYb//jhAL/693pWnjYa7NTs5/PdCOCt8er1o/n6nqb7FDojjwWCs21QTBBmo2LHcccC5EEWM3PGxLNkV0armyROl11cyW3vbeFgOyTcaqkVydn8cdHOBjtKi8qrMSjFI5/v5o7/JLXJ0p8fbUrjRGEFoX5mrjunB1eOjOXVFSlufWm78vLcUSyYd069bVprrn1zIw9+srPJ41ceyGFinwi37xZfW5HCuL/9TGW1jRqbnce/2kNsiIXfTa+fQz421I+LBkfzyZbjbucoevyrPVw9fwNX/Xs9l7+ylpkvruG+j7fXvn7fwu3c/d9tvPTzIX7Yk8GRnFK3/03eWZtKVJDvGaN1GjNrRCx2zRkLmSilGJcQ3uiksbbg52Nk0V3nEh/uz7wFW3hvXWptDfWHPZkM7B5UL62EJ/iYDAyPD/Xoe3RUnWY5Jl+TkcExwbXttwC3TkogoVsAfm08U9RsNLA/o5iXlx3i1etbPCH6rCmqqOZPX+wm2M+Eyej6DjEq2MInv53A22tS+dt3+/nXTwd4ZObAFr9nSnYpm1PzeWTmwNoZmn+7ahi/npxIVJB7TTl1aa1RSp3RPKGU4uIh0fzfd8lsPVbQYLVea82r149qVoAbEB1EVY2dnccLSc4sITmzhH/fMNrl/INbzu3N93sy+WrHiQY7NCurbRRXVhMVZOGpWUMprLBSY9NU2+zU2HW9Ic9KwZ70Ir7bncGpFruhccF8+btJmJtYhvC+C/qRV1qFj8n9+7x+0UEMignm650nuW1SQu32z5KO0ysigHGNjBhqK3Ghfiy6cyIPfLKDp77ZR0p2Kfdf0I8tx/JrJ8EJz+g0gQAczUNfbDuBze4YNpfQLYCEbglNH9gM765N5ZJh3bnl3N68vuowD2SX0NeNnCTt6W/f7iOntIo3bx7TaDuvUorfnJfIkdxSXl95mBHxoQ2uzdqUjzenYTIo5oyJr90W4GtiWLxjMtP6w7mMT4jA6OY0/rs+3EZUsC9Pzx56xms3jO/F/FVHeGX5IRbcNq7eazuPF/Ll9hM8ccVghsQ2L3/QOQnhKAUbj+QTZDExY1B0g7NaxyeEM7B7EAvWH+OasT1cNsk8+fVeliVns+yhqbXXoSEvXTcKcDSZpGSXkpxZzMQ+EU0GAXCskNUSN0/sVVvzMBoUNTY7Ty/Zx2XDYs5KIADH/5E3bhzDP386QICPkZ/2ZaG1Y1io8JxO0zQEMCI+lNKqmnqjYKptdj7ceIzb39/Cw5/t5Ia3NzL9Xyv554+OhSlyS6t4feVhtzpK1x7K5ekl+/h8azq3T0nEz2xst8U53LXyQDafJqXz2/MS3a72PjlrCDdO6MnIFi7kXlVj4/Nt6Vw0JLp2Tkdd29MKuP6tTbyy/JBb5yurqmF5cnaDX4IBviZun5LAygM5tTVCrTXvrz/KnPnrWbovi+yS5jcPhviZGRwTzMYjecybnMBbN49psM1dKcVd0/owbUAkVhdDcr/cns7HW45z9Zj4Zk129PMxMiw+hKvH9iA+zJ8am53HFu+uV/M9paDMyuNf7eFEYaNpwBo0d1xP/veywbXBeWd6ISWVNZzXv+Fho55gMCgemTmQe87vx5wx8fzn1+PoHy1rjXhS5woEzi+uuiOFDEqxYP1RliVns/ZQLhVWG0Nig2sXsVm8/QTP/pDMO2sbH5FgrbHz+Nd76BXhz+3OzsKbJvbim50nOezB4Zen7D1ZRFVN83Lk2+2OBTb6RQVy/wz3q9a+JiPPXDmM7iEWbC2YfGa3O/LSzJvkujY2skcovxodx0vLDrHOjYRn61JysdrsXNBIZ+HNE3sT6m/m823pFFdWc89/t/PE13s5r18k3943+YzRP+4a2D2YDUfyqLHZm+x4nT0yjkdmDjyj1pWSXcr/frmHcb3DebCBpQXdVVhRzaqDOdzy3uYz+qj+uzmNDzYca3LCXGNsds2Wo445H6sO5mJQjpnA7cViNjKl35lZYkXb6lRNQ4ndAgjyNbEzvZCrxzrmqhkNiu/vnwLg8o5y3qQEko4W8H/f7Wdg9+AG83a/uy6VIzllvHvr2NrOxt9MSaSwrNoj2SqLK6tZeyiXS4fFUFltY+6bGzEYFFcMj+VXo+MY2SO0yT8Og0GxYN44SiqrWzT0T2vNb/+ThNbw1s1j3c7G6Odj5PYpDWcpd0w+Gsqu9CLu/3g7399/nsuawynL9mcT5GtqdGZroK+Jz+86l4SIAK55YwPbjxfy6CUDuWNKotvlduX2KQlU1diw2uyY3GiWsds1Kw9mMyQ2hOhgCxVWG3d/tA0/s5GX545y6xyN6Rboy0e/nsCc+eu58e1NLLrzXHpG+GOtsfPBhqNM6detVfMaPtlynD9/uZsfHpjC6oM5jOgRSoi/pGvp7DpVjcBgUAzvEcJO58ihU8xGQ4PNCgaD4l/XjKBvVCD3LNxGWt6ZQ/gyiip4edkhZgyKqjcVv1ugL8/OGU5cqN8Zx7RUhdXGG6sOc94/VnDPf7dxsrACs9HAK9ePZmr/SD7bepyr/r2eC55bVTvMLrukkhXJ2Xy06Rj/+vEADzrzwuSXWYkL9Wty5mhDlFJM6RfJsuRsXnazGSctr5zPkpoePePvY+LfN4ympLKGPy7a2WDTnN2uWX4gm/MGRDbZPt4nMhCDQfHQRQP4+I4J3Dm1T6uCADhmnb56vesOYldOFlVw+/tJtUnMqu12ekX48/y1I92e79CUnhH+fHj7eKptdq5/eyOZRZV8vyeDrOIq5k1uXZ/YRUOiMRoUnyWlczy/nPMamU0sOo9OVSMARz/Bm6uPUFltc/tOPdDXxFs3j2XWq+t4esle3r6l/hBFX5OR2SPjuGtqH5fH7zlRxLa0Am6e2LvF5a622flky3FeXnaI7JIqpvaP5A8XDyDWGWSm9nfMdC2prOb73Zl8vi29dh2GFcnZPPL5bsBRA+oebCEmxEJZVU2zlrRz5eaJvdiZXsiLPx9iWFwIFwxqfNboR5uP8faaVKb2j2zy+vePDuLJWUMa/YK32uxcP64nI3uGul3miW7MHPaU+DB/LhgUzcLNx7n3/H4EW8y8efPYNn+f/tFBvD9vHL/5IInjBeW8szaVxMiARtNAuKNboC+T+nbjx72ZbPrzBS77O0TnozpisqzGjB07ViclNTz37Me9mfz2P1v54nfnMrpn82YIbksrICEioNkpaJ/6Zi8fbDjGioemuUyy5Y7s4krO++cKhsSG8MeLBzC+GZOesksqOZ5fTmyoH5GBvq1ufjhdZbWNOfPXcyy3nK/umdTgeG5rjZ2J/28ZY3uH8cZNzf/yOzVE1NutS8nlhrc3AbD2keanOmiOUzWvp77Zx6geoVzTRFI2dyzams7Dn+3k87vO7ZKzbDsrpdRWrbXLP8xO1TQE1I50cTWqoimje4YRFuCDtcbOygPZVNscaRH2nChq9Lg7p/bBaFD8e2XzRxDlOEezRAVb+O6+KSy6c2KzggBAVJCFMb3CiQnxa/MgAI4Ou/k3jiEswKfRsek/788ir8zaogW8v9yeztXzN5zRIb7xSF6TufI7mnP7RNAt0HEz4c5wz9awmI1YzEb+36+GtUkQALh4iKPWt2jr8Sb2FJ1FpwsE0cEWugdbWhQITnlz9WFuW7CFe/+7nS+3nyCzqPGZsNHBFuae04NFW9OblSZg67ECZjy/ivedaTASIwM77B1xfJg/P/3+POLDHCtMvfjzQTKK6g9TXLg5jbhQP6a0oHkiyNdM0rECnvvpYO22rOJKrntzI++tdy/HTEehlOK7+6ew+c8XtHi0UnsKspj59LcTuXu6Z9NKiI6j0wUCgOHxIexMb/wuvjG3T0lkSGwwP+zN5PyBUW5lU7xzWh8MSvH6qsNuvcfy5CxueHsjYf5mpg/wbA6VtnKqzT8lu5Q3Vh3hohdWs2hrOlprKqttFJRbufacHm5PEqtrxuBobhjfkzdXH6kdUro82dEZfkEjufI7qqggS20yP280LiG8S+bc6ao6ZSAY0SOU1NwyCsutTe/sgsVs5I2bxjJnTDxPzx7i1jExIX7cNrk3UY0Mgzzl863p/OaDrfSLCmLRXee2uF+hvfSLDuL7+6cwsHsQD3+2k9vfT6Koopol907hd9Ncd6i747HLBpMYGcBDn+6ksNzKsv3ZxIX6yWQiITysUwaCkbWZSFteK4gL9eNfV49o1l3Rny4ZxAMz+pNZVEnS0XyO5JRSVFFdb2hkam4Zf1i0kwmJ4Sy8YwLdApsOHB1R724BfHLHRP5y+WDWpuRy8zub0Vq3qo/Cz8fIy9eNIr/MypJdGaxNyWHGoKgO21wmRGfR6YaPArV5XHYeLzzr0+MBftqXyeNf7a393WxURAT48tmdE0noFsB7t43zWH73s8lgUPx6cgLTB0SSV2Ztky/soXEhLH94KinZpVRW2zm/ieGqQojW65SBINhipk9kADudaxOcbRcP6U7viADyy6zkllaRV2Ylr7SKUOcMzantEJw8KTEykMQ2/EjxYf7EhvjxzT2T6d9dmoWE8LROGQjA0U+w+mBuu4xNjw62eOVokY7EYFBNZugUQrSNTtlHAI5+gtzSKk42MfRTCCG6uk4bCEY4Uy63Zj6BEEJ0BZ02EAyMCcLHaGi3fgIhhPAWnTYQ+JqMDIoNlhqBEEI0odMGAoCR8SHsTi9qk4XYhRCis+rUgWBEj1DKrLazsoKYEEJ4q04fCKD+0pVCCCHq69SBICEigCCLSfoJhBCiEZ06EBgMihHxoTJySAghGtGpAwHAiB4hJGeUNLmGrhBCdFWdPxDEh1Jj1+w9WdzeRRFCiA6p0weC1ixdKYQQXUGnDwRRwRbiw/z4cW9mexdFCCE6pE4fCADmTUpgU2o+6w/ntndRhBCiw+kSgeD68T2JDvblhaUH660WJoQQoosEAovZyD3T+7LlaAFrDkmtQAgh6uoSgQDgmnN6EBti4XmpFQghRD1dJhD4mozce0E/dhwvZMWB7PYujhBCdBhdJhAAzBkTT49wP6kVCCFEHV0qEJiNBu47vx97ThTz076s9i6OEEJ0CB4NBEqpmUqpA0qpFKXUoy5en6aUKlJK7XA+HvdkeQCuGhVHQrcAXlh6ELusUyCEEJ4LBEopI/AacAkwGJirlBrsYtc1WuuRzsfTnirPKSajgfsv6EdyZgnf75FJZkII4ckawTggRWt9RGttBT4GZnvw/dx2xYhY+kYF8uLPB2X1MiFEl+fJQBAHHK/ze7pz2+kmKqV2KqW+V0oN8WB5ahkNigdm9ONQdilLdp08G28phBAdlicDgXKx7fTb721AL631COAVYLHLEyl1h1IqSSmVlJOT0yaFu3RoDAO7B/HSz4eosdnb5JxCCOGNPBkI0oEedX6PB+rdfmuti7XWpc7n3wFmpVS300+ktX5Taz1Waz02MjKyTQpnMCgemNGfI7llvL7ycJucUwghvJEnA8EWoJ9SKkEp5QNcB3xddwelVHellHI+H+csT54Hy1TPxUOiuWJELM8tPcjfv0+WuQVCiC7J5KkTa61rlFL3AD8CRuBdrfVepdSdztfnA3OAu5RSNUAFcJ0+i9/GSilevHYkwRYT81cdpqDMyt+uGorJ2KWmVwghujjlbXfBY8eO1UlJSW16Tq01Lyw9yMvLU7h4SDQvXTcKi9nYpu8hhBDtSSm1VWs91tVrcuuLo2bw4EUDePzywfy4N4vb3ttCSWV1exdLCCHOCgkEdcybnMAL145g89F8rn9rE3mlVe1dJCGE8DgJBKe5alQ8b908hoNZJVw9fwNpeeXtXSQhhPAoCQQunD8wmg9vH09emZVZr61lXYosZiOE6LwkEDTgnN7hfH3PJKKCfLn53c28szZVhpcKITolCQSN6BURwBe/m8QFA6P465J9PPzZLiqrbe1dLCGEaFMSCJoQ6Gti/o1jeGBGPz7fls61b24kq7iyvYslhBBtRgKBG06lo5h/4xgOZZVwxStr2ZZW0N7FEkKINiGBoBlmDu3OF787F4vZyLVvbOCZJfsoqpD5BkII7yaBoJkGdg/m63sm8atR8byzLpVp/1zBfzYclQymQgivJYGgBUL9fXh2znCW3DuZAd2D+MtXe7nkpTWsPJDd3kUTQohmk0DQCkNiQ1j4mwm8cdMYrDY7t763hVve3cyhrJL2LpoQQrhNAkErKaW4eEh3lv5+Ko9dNohtaQXMfGkNf1m8R1JUCCG8ggSCNuJjMnD7lERW/WE6N47vyX83pzHtnyuZv+qwzD0QQnRoEgjaWHiAD0/NHsqPD5zHuIRw/v59MjOeX8U3O082OjO5stomM5eFEO1C1iPwsHUpuTzz7X72ZxQzumcolw2PJbe0iqziSrKLHT+ziisprqxhQHQQv7+wPxcPica5cJsQQrSJxtYjkEBwFtjsms+3pfOvHw+QXVKF2aiICrIQFexLdJCF6GBfQv19+GbXSY7klDE0LpgHL+zP9AFREhCEEG1CAkEHUVVjo7SyhjB/HwyGM7/ga2x2Fu84yUvLDnI8v4JRPUN56MIBTOobgVIKrTUZRZXsPVnM3pNF7D1ZTFZxJXdP78vFQ7q3wycSQngLCQReptpmZ9HWdF5ZdoiTRZWM7RWGxWxk78kiCsodM5mVgoSIAACO5JZx9/Q+PHjhAIwuAowQQjQWCDy2eL1oObPRwNxxPfnV6Dg+3nyc99alEmgxcdHg7gyODWZIbDCDYoIJ8DVRWW3jya/38tqKw+xKL+Ll60YRFuDT3h9BCOFFpEbQSSzcnMYTX+0lKtiX+TeOYWhcSHsXSQjRgcji9V3A3HE9+fTOidjsmv95fT2Ltqa3d5GEEF5CmoY6kZE9Qlly72TuXbidhz/bybqUXPpFB2I2GDAbFSajAR+jAZNRER7gw+heYQRbzO1dbCFEO5NA0MlEBPrywbxx/POnA7y9JhWbveGmP4OCwbHBjE+IYHxCOOMSwgn1d/QvaK3JKq7iQFYJBzKLOZBZSkpOKaN6hPLgRf0lgAjRiUgfQSdWY7NTY9dYbXZqbJpqm9350GQUVrAxNZ9NR/LYfrwQa40dpWBAdBDBFjMHskrqrbUQFeRLz3B/tqYVEBXky5NXDGHm0O4yz0EILyHDR0Wjqmps7DxexKYjeWxKzaey2kb/7kEM7B5E/+ggBkQH1Y5E2nm8kD99sZt9GcXMGBTF07OHEhvq16L31VqTW2rFx2jA12zA12SQwCKEh0ggEG2qxmbn3XWpvLD0EErBQxcN4NZzezc5h6HaZmfPiSKSjhaw+Wg+SUfza+dFnOJjMmAxGfA1G4kP8+OWib25bHgMZqOMaxCiNSQQCI84nl/OX77aw8oDOQyLC2FinwiUAqNSGJTCYFAYFFTV2Nl5vJDtaYVUODOx9orw55ze4QyJDcauHbWSymo7VTU2qpw/N6fmczinjNgQC/MmJ3DduJ4E+rZtt1ZltY0luzJYcyiHWSNiOX+gpPUQnZMEAuExWmuW7Mrg2R+SySu1Ytfa+aC2o9qgYFBMMOf0Dnc+wogKtjR5brtds+JANm+uPsKm1HyCLCauH9+TeZMSiHbj+MakF5Tz4cY0PtmSRkF5NX5mIxXVNiYkhvO/lw5mWLzMwxCdiwQC0W601miNy9xKzbHjeCFvrTnC97szMBoU5w+MYlxCBOf0DmNwTDAmN5qOtNasTcnlgw3HWLY/C4ALB0dzy8TejO0dzsdb0njx50Pkl1mZPTKWhy8aQI9w/1aVW4iOQgKB6DTS8sp5d10qP+/PIr2gAgB/HyOje4YxtncY5/QOx2I2kFn0S4pvx6OKY3llnCyqJCLAh+vG9eD68b2IO62ju6SymvmrDvP2mlS0hlsn9ebuaX0J8XcMl9XO2o5da2x2jcmg3ApCnlRQZuVIbinD40OlL6UTWHMoh1eXp3Dn1D5MHxjVZueVQCA6pYyiCpKOFpB0NJ/NRwtIzizm9P/OPiYD0afSfYdYmDEoikuHxeBrMjZ57ud+Osjn29JRgEEpbM7azemCLSYiAn0J8zcTHuBLeIDjZ6i/mRC/+o9gi+NnkMXUqlpSWVUNS/dl8fXOk6w+mEONXRPqb2bmkO5cMSKW8QnhbR6gtNasPJDDR5vS6BMZwFWj4xjYPbhN36Mrs9s1/16ZwnNLD2IyKKptmt+el8jDFw9okwAvgUB0CcWV1exIK8SuNd1DLEQHWQj1N7eq83ffyWK+3X0SrcFoUCilnJ3hjuYua42dwnIreWVWCsqt5JdVk19WRX6ZlWpb45P5Qv19CPU3E+7vQ6i/jzOQ+BAe4EO3QF8iAh0/uwX6Eh7gg935RfzNrpMs259FZbWdmBALV4yIZWhcCMv3Z7F0XxZlVhvdAn24ZGgMV4yIZWyvsFYFHa01y5OzeWnZIXalFxEZ5EtBmZUau2ZwTDC/Gh3HrJGxRAW1rt+mve09WcQX205QUGalqKK63qO4sppgi5kbJ/Ti+vE96Rbo26bvXVRezYOf7mBZcjazR8byxBVDeO6nA3y0KY1RPUN5+bpRrW6mlEAgxFmmtabcavvli+S0L5aiimryy6wUlldTUG6loLyawnIr+WVWqmrsLs9pNjruEiMCfLh0mOsv+cpqGyuSs1myK4NlyY5gEeBjJMIZTMIDfAjz9yEi0PEzJsRCQrcAEiMDCDpttrjWmmX7HQFg94kieoT7ce/0flw1Oo7iimq+2XmSL7efYGd6EQYFk/tFcuXIWEb1DKNnuL/XpEQvrarh+Z8OsmB9Kmajgcgg33q1txA/MyH+Zg5mlbDyQA4+JgNXjozltkkJDIppfY1o78ki7vpwGxlFFTx22WBuntir9uZlya6T/Onz3SgF/5gznJlDY1r8PhIIhPASWmvKrDbySqvILa0it9RKbmkVeaVWyqpqOLdvNyb1iXCr2aesqoaf92exPa3QWVtxPArKHDWY0wNOZJAvCd0C6BMZQHyYP9/vyWDPiWJ6Rfhz9/S+XDUqzmUTRUp2KYu3n+DL7Sc4Uejot/E1GegbFUj/6CDnI5DYUD8KyqxklziXai2pcjyKK6msthHgayLQ10SgxUSQr8nxu8WEj9FQOxLN7myes9kdo9NC/MzEhPgRG2ohJsSPboE+btcAtdZ8tzuTp5fsJbukiuvH9eSPFw+s7Q9yJSW7lAXrU/l86wkqqm1MTIxg3uQEzh8Y1aLA91nScR5bvIcwfx9eu2E0Y3qFnbFPWl459yzcxq70Im6Z2Is/XToIi7nxpk1XJBAIIeo5VWM5WVjBkdwyjuSUkZpb6vxZRl6ZlV4R/tx7fj+uHBnrVuCx2zV7ThaRnFnCwcwSDmaXcjCzhMziSpf7+5mNRAX7EhXki7+PibKqGkrrPEoqaxrNleWKj9FATKiFmBALA6KDGBoXwrD4EPpGBtb7DMfyyvjLV3tZfTCHIbHBPHPlUEb1PPNLuCGF5VY+3nKc99cfJaOoku7BFi4eEs3FQ7szrnfj/TMVVhvb0gr4YtsJPt+Wzrl9Inh57qhGm5usNXae/SGZd9am0jcqkAsGRTGqRyijeoa5PZRaAoEQolmKK6sJ8DG1SfNOUUU1h7IcASEiwLf2yz/Q19To3bvWmspqOzV2u2OColIo5ei4NxoUCigot5JRVMmJwgoyCivIKKrkZFEl6QXlHMgsodzqmMBoMRsYFBPMsLgQLGYjC9Yfxcdo4KGL+nPThF4t7livttn5cW8mX+84yaqDOVTV2AnzNzNjUDQXD+nO5H7dsNk1W48VsCk1j01H8tmZXki1TWM0KO44L5GHLuzv9vv/vC+LV1eksPdkUW0fVGyIhZE9QxnVI4zYUD9ySirJLHbUtLJKHCPmsoor2fPUzPYJBEqpmcBLgBF4W2v999NeV87XLwXKgVu11tsaO6cEAiGEO2x2TWpuKbtPFLE7vZg9J4rYe7KIMquNy4fH8JfLB7d6YmJd5dYaVh/M4Yc9mSxLzqaksgY/s5FqZ/JHo0ExLC6E8YnhTEiMYGyvsDP6ZdxVWW1jX0Yx29MK2XG8kO1pBbXDqcHRnxQVZHGMmAu2EB1s4anZQ89+IFBKGYGDwIVAOrAFmKu13ldnn0uBe3EEgvHAS1rr8Y2dVwKBEKKl7HZNUUW1x5dztdbY2XAkj2X7swj0NTE+MYIxvcLaPEVKXTklVeSUVBEd7EuYv88ZI8Xaa83icUCK1vqIsxAfA7OBfXX2mQ18oB3RaKNSKlQpFaO1zvBguYQQXZTBoM7Kmt4+JgNT+0cytX+kx9/rlMggXyKDWjas1ZPTEOOA43V+T3dua+4+KKXuUEolKaWScnJy2rygQgjRlXkyELjqBTq9HcqdfdBav6m1Hqu1HhsZefYirBBCdAWeDATpQI86v8cDJ1uwjxBCCA/yZCDYAvRTSiUopXyA64CvT9vna+Bm5TABKJL+ASGEOLs81lmsta5RSt0D/Ihj+Oi7Wuu9Sqk7na/PB77DMWIoBcfw0ds8VR4hhBCueXLUEFrr73B82dfdNr/Ocw3c7ckyCCGEaJwkLxdCiC5OAoEQQnRxXpdrSClVAhxo73J0MN2A3PYuRAci16M+uR5n6orXpJfW2uX4e4/2EXjIgYamSXdVSqkkuSa/kOtRn1yPM8k1qU+ahoQQoouTQCCEEF2cNwaCN9u7AB2QXJP65HrUJ9fjTHJN6vC6zmIhhBBtyxtrBEIIIdqQBAIhhOjivCoQKKVmKqUOKKVSlFKPtnd5zjal1LtKqWyl1J4628KVUkuVUoecP91fgdvLKaV6KKVWKKX2K6X2KqXud27vytfEopTarJTa6bwmTzm3d9lrAo4VE5VS25VSS5y/d+nrcTqvCQTOpS9fAy4BBgNzlVKD27dUZ90CYOZp2x4Flmmt+wHLnL93FTXAQ1rrQcAE4G7n/4mufE2qgPO11iOAkcBMZ2bfrnxNAO4H9tf5vatfj3q8JhBQZ+lLrbUVOLX0ZZehtV4N5J+2eTbwvvP5+8CVZ7NM7UlrnaG13uZ8XoLjDz2Orn1NtNa61Pmr2fnQdOFropSKBy4D3q6zucteD1e8KRC4taxlFxR9ag0H58+odi5Pu1BK9QZGAZvo4tfE2QyyA8gGlmqtu/o1eRH4I2Cvs60rX48zeFMgcGtZS9H1KKUCgc+BB7TWxe1dnvamtbZprUfiWPFvnFJqaDsXqd0opS4HsrXWW9u7LB2ZNwUCWdbStSylVAyA82d2O5fnrFJKmXEEgY+01l84N3fpa3KK1roQWImjX6mrXpNJwCyl1FEczcnnK6U+pOteD5e8KRC4s/RlV/Q1cIvz+S3AV+1YlrNKKaWAd4D9Wuvn67zUla9JpFIq1PncD5gBJNNFr4nW+k9a63itdW8c3xnLtdY30kWvR0O8amaxUupSHO19p5a+/Fv7lujsUkotBKbhSKGbBTwBLAY+BXoCacDVWuvTO5Q7JaXUZGANsJtf2n//jKOfoKtek+E4Oj+NOG70PtVaP62UiqCLXpNTlFLTgIe11pfL9ajPqwKBEEKItudNTUNCCCE8QAKBEEJ0cRIIhBCii5NAIIQQXZwEAiGE6OIkEAjhpJSyKaV21Hm0WSIypVTvulljhehITO1dACE6kApnagYhuhSpEQjRBKXUUaXUs848/5uVUn2d23sppZYppXY5f/Z0bo9WSn3pXBNgp1LqXOepjEqpt5zrBPzknPmLUuo+pdQ+53k+bqePKbowCQRC/MLvtKaha+u8Vqy1Hge8imN2O87nH2ithwMfAS87t78MrHKuCTAa2Ovc3g94TWs9BCgE/se5/VFglPM8d3rmownRMJlZLISTUqpUax3oYvtRHIu9HHEmucvUWkcopXKBGK11tXN7hta6m1IqB4jXWlfVOUdvHCmh+zl/fwQwa62fUUr9AJTiSBeyuM56AkKcFVIjEMI9uoHnDe3jSlWd5zZ+6aO7DMfqe2OArUop6bsTZ5UEAiHcc22dnxucz9fjyGgJcAOw1vl8GXAX1C4SE9zQSZVSBqCH1noFjsVTQoEzaiVCeJLceQjxCz/nyl6n/KC1PjWE1FcptQnHzdNc57b7gHeVUn8AcoDbnNvvB95USv0ax53/XUBGA+9pBD5USoXgWHzpBec6AkKcNdJHIEQTnH0EY7XWue1dFiE8QZqGhBCii5MagRBCdHFSIxBCiC5OAoEQQnRxEgiEEKKLk0AghBBdnAQCIYTo4v4/a1kDoilxaJkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def MLP(img_size):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(img_size, img_size, 3)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=512,activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(units=256,activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(units=43,activation='softmax'))\n",
    "\t\n",
    "    return model\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    train_images, test_images, train_labels, test_labels = get_images_and_preprocessing(28)\n",
    "    \n",
    "    print(train_images.shape)\n",
    "    print(type(train_images))\n",
    "    \n",
    "    \n",
    "    # 지시사항 2에서 설정한 모델을 불러옵니다.\n",
    "    model = MLP(28)\n",
    "    \n",
    "    # 모델의 구조를 확인합니다.\n",
    "    model.summary()\n",
    "    \n",
    "    # 컴파일러를 설정합니다.\n",
    "    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    # fit 함수를 사용하여 모델을 학습합니다.\n",
    "    # 학습 수행 시 정보는 history에 저장합니다.\n",
    "    history = model.fit(train_images, train_labels, epochs=50, batch_size=256,validation_data=(test_images, test_labels),verbose=2)\n",
    "    \n",
    "    # evaluate 함수를 사용하여 테스트 데이터의 결과값을 저장합니다.\n",
    "    loss, test_acc = model.evaluate(test_images,test_labels)\n",
    "    \n",
    "    print('\\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))\n",
    "    print('예측한 Test Data 클래스 : ',model.predict_classes(test_images))\n",
    "    \n",
    "    Visualize([('MLP', history)], 'loss')\n",
    "    \n",
    "    return test_acc\n",
    "\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도 : 0.91\n",
    "epoch = 20, batch_size = 256, image_size = 28, Conv = 3 (relu, relu, relu), Dense = 1(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_images_and_preprocessing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ecdf6c908ac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-ecdf6c908ac9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_images_and_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_images_and_preprocessing' is not defined"
     ]
    }
   ],
   "source": [
    "def CNN(img_size):\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(img_size,img_size,3)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding=\"SAME\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D(2,padding=\"VALID\"))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding=\"SAME\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D(2, padding=\"VALID\"))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding=\"SAME\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D(2, padding=\"VALID\"))\n",
    "    \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(43, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n",
    "def main():\n",
    "    \n",
    "    train_images, test_images, train_labels, test_labels = get_images_and_preprocessing(28)\n",
    "    \n",
    "    print(train_images.shape)\n",
    "    print(type(train_images))\n",
    "    \n",
    "    \n",
    "    # 지시사항 2에서 설정한 모델을 불러옵니다.\n",
    "    model = CNN(28)\n",
    "    \n",
    "    # 모델의 구조를 확인합니다.\n",
    "    model.summary()\n",
    "    \n",
    "    # 컴파일러를 설정합니다.\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "    model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    # fit 함수를 사용하여 모델을 학습합니다.\n",
    "    # 학습 수행 시 정보는 history에 저장합니다.\n",
    "    history = model.fit(train_images,train_labels, epochs=20, batch_size=256, validation_data=(test_images, test_labels), verbose = 2)\n",
    "    \n",
    "    # evaluate 함수를 사용하여 테스트 데이터의 결과값을 저장합니다.\n",
    "    loss, test_acc = model.evaluate(test_images,test_labels, verbose=2)\n",
    "    \n",
    "    print('\\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))\n",
    "    print('예측한 Test Data 클래스 : ',model.predict_classes(test_images))\n",
    "    \n",
    "    Visualize([('CNN', history)], 'loss')\n",
    "    \n",
    "    Plotter(test_images, model)\n",
    "    \n",
    "    return test_acc\n",
    "\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도 : 0.9\n",
    "epoch = 5, batch_size = 2, image_size = 128, Conv = 3 + Pooling = 3 (relu, relu, relu), Dense = 3 (relu,relu,softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 128, 128, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 124, 124, 6)       456       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 62, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 58, 58, 16)        2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 29, 29, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 13456)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               1614840   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 43)                3655      \n",
      "=================================================================\n",
      "Total params: 1,631,531\n",
      "Trainable params: 1,631,531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "19605/19605 - 418s - loss: 0.6482 - accuracy: 0.8145 - val_loss: 0.6226 - val_accuracy: 0.8659\n",
      "Epoch 2/5\n",
      "19605/19605 - 376s - loss: 0.2212 - accuracy: 0.9390 - val_loss: 0.5367 - val_accuracy: 0.8835\n",
      "Epoch 3/5\n",
      "19605/19605 - 371s - loss: 0.1793 - accuracy: 0.9553 - val_loss: 0.6808 - val_accuracy: 0.8779\n",
      "Epoch 4/5\n",
      "19605/19605 - 373s - loss: 0.1654 - accuracy: 0.9619 - val_loss: 0.8647 - val_accuracy: 0.8779\n",
      "Epoch 5/5\n",
      "19605/19605 - 373s - loss: 0.1632 - accuracy: 0.9668 - val_loss: 0.7501 - val_accuracy: 0.9053\n",
      "395/395 - 10s - loss: 0.7501 - accuracy: 0.9053\n",
      "\n",
      "Test Loss : 0.7501 | Test Accuracy : 0.9053048491477966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/LG/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측한 Test Data 클래스 :  [16  1 38 33 11 38 18 12 25 35]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def LeNet(img_size):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    '''\n",
    "    지시사항 1번\n",
    "    LeNet 구조를 완성하세요.\n",
    "    '''\n",
    "    # Conv 1 Layer\n",
    "    model.add(Conv2D(filters=6, kernel_size=5, strides=1, activation=tf.nn.relu, input_shape=(img_size,img_size,3)))\n",
    "    \n",
    "    # Sub Sampling Layer (Max Pooling)\n",
    "    model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "    \n",
    "    # Conv 1 Layer\n",
    "    model.add(Conv2D(filters=16, kernel_size=5, strides=1, activation=tf.nn.relu, input_shape=(16,16,3)))\n",
    "            \n",
    "    \n",
    "    # Sub Sampling Layer (Max Pooling)\n",
    "    model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "    \n",
    "    # Fully Connected (FC) Layer와 연결하기 위한 Flatten\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # FC1 Layer \n",
    "    model.add(Dense(units=120, activation=tf.nn.relu))\n",
    "    \n",
    "    \n",
    "    # FC2 Layer\n",
    "    model.add(Dense(units=84, activation=tf.nn.relu))\n",
    "    \n",
    "    \n",
    "    # Output Softmax\n",
    "    model.add(Dense(units=43, activation=tf.nn.softmax))\n",
    "    \n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n",
    "def main():\n",
    "    \n",
    "    train_images, test_images, train_labels, test_labels = get_images_and_preprocessing(128)\n",
    "\n",
    "    print(train_images.shape)\n",
    "    print(type(train_images))\n",
    "    \n",
    "    \n",
    "    # 지시사항 2에서 설정한 모델을 불러옵니다.\n",
    "    model = LeNet(128)\n",
    "    \n",
    "    # 모델의 구조를 확인합니다.\n",
    "    model.summary()\n",
    "    \n",
    "    # 컴파일러를 설정합니다.\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "    model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    # fit 함수를 사용하여 모델을 학습합니다.\n",
    "    # 학습 수행 시 정보는 history에 저장합니다.\n",
    "    history = model.fit(train_images,train_labels, epochs=5, batch_size=2, validation_data=(test_images, test_labels), verbose = 2)\n",
    "    \n",
    "    # evaluate 함수를 사용하여 테스트 데이터의 결과값을 저장합니다.\n",
    "    loss, test_acc = model.evaluate(test_images,test_labels, verbose=2)\n",
    "    \n",
    "    print('\\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))\n",
    "    print('예측한 Test Data 클래스 : ',model.predict_classes(test_images)[:10])\n",
    "    \n",
    "    Visualize([('LeNet', history)], 'loss')\n",
    "     \n",
    "#     오류해결해야함\n",
    "#     Plotter(test_images, model)\n",
    "    \n",
    "    return test_acc\n",
    "\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. VGGNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도 : 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 128, 128, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 43)                22059     \n",
      "=================================================================\n",
      "Total params: 50,392,939\n",
      "Trainable params: 50,392,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ff95b572eaff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-ff95b572eaff>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# fit 함수를 사용하여 모델을 학습합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# 학습 수행 시 정보는 history에 저장합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# evaluate 함수를 사용하여 테스트 데이터의 결과값을 저장합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def conv(filters, kernel_size = 3, activation= tf.nn.relu, padding= 'same'):\n",
    "    return keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, activation= activation, padding= padding)\n",
    "\n",
    "def VGG16(img_size):\n",
    "    # Sequential 모델 선언\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    '''\n",
    "    지시사항 1번\n",
    "    3 x 3 convolution만을 사용하여 VGG16 Net을 완성하세요.\n",
    "    '''\n",
    "    # 첫 번째 Conv Block\n",
    "    # 입력 Shape는 ImageNet 데이터 세트의 크기와 같은 RGB 영상 (224 x 224 x 3)입니다\n",
    "    model.add(Input((img_size, img_size, 3)))\n",
    "    model.add(conv(64))\n",
    "    model.add(conv(64))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    \n",
    "    # 두 번째 Conv Block\n",
    "    model.add(conv(128))\n",
    "    model.add(conv(128))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    \n",
    "    # 세 번째 Conv Block\n",
    "    model.add(conv(256))\n",
    "    model.add(conv(256))\n",
    "    model.add(conv(256))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    \n",
    "    # 네 번째 Conv Block\n",
    "    model.add(conv(512))\n",
    "    model.add(conv(512))\n",
    "    model.add(conv(512))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    \n",
    "    # 다섯 번째 Conv Block\n",
    "    model.add(conv(512))\n",
    "    model.add(conv(512))\n",
    "    model.add(conv(512))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    \n",
    "    # Fully Connected Layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(4096, activation= tf.nn.relu))\n",
    "    model.add(keras.layers.Dense(512, activation= tf.nn.relu))\n",
    "    model.add(keras.layers.Dense(43, activation= tf.nn.softmax))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n",
    "def main():\n",
    "    \n",
    "    train_images, test_images, train_labels, test_labels = get_images_and_preprocessing(128)\n",
    "\n",
    "    print(train_images.shape)\n",
    "    print(type(train_images))\n",
    "    \n",
    "    \n",
    "    # 지시사항 2에서 설정한 모델을 불러옵니다.\n",
    "    model = VGG16(128)\n",
    "    \n",
    "    # 모델의 구조를 확인합니다.\n",
    "    model.summary()\n",
    "    \n",
    "    # 컴파일러를 설정합니다.\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "    model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    # fit 함수를 사용하여 모델을 학습합니다.\n",
    "    # 학습 수행 시 정보는 history에 저장합니다.\n",
    "    history = model.fit(train_images,train_labels, epochs=5, batch_size=256, validation_data=(test_images, test_labels), verbose = 2)\n",
    "    \n",
    "    # evaluate 함수를 사용하여 테스트 데이터의 결과값을 저장합니다.\n",
    "    loss, test_acc = model.evaluate(test_images,test_labels, verbose=2)\n",
    "    \n",
    "    print('\\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))\n",
    "    print('예측한 Test Data 클래스 : ',model.predict_classes(test_images))\n",
    "    \n",
    "    Visualize([('VGGNet', history)], 'loss')\n",
    "     \n",
    "    Plotter(test_images, model)\n",
    "    \n",
    "    return test_acc\n",
    "\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도 : 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters):\n",
    "    \n",
    "    filters1, filters2, filters3 = filters\n",
    "    \n",
    "    x = Conv2D(filters1, (1, 1))(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    '''\n",
    "    지시사항 1번\n",
    "    아래 내용을 채워 identity_block()을 완성하세요.\n",
    "    '''\n",
    "    # 입력(x) : input_tensor와 F(x) : x를 더해줍니다.\n",
    "    # TODO : add()와 Activation() 메서드를 사용해서 relu(F(x) + x) 의 형태로 만들어보세요. \n",
    "    x = add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def residual_block(input_tensor, kernel_size, filters, strides=(2, 2)):\n",
    "    filters1 , filters2 , filters3 = filters\n",
    "    \n",
    "    # 입력 Feature Map의 Size를 1/2로 줄이는 대신 Feature map의 Dimension을 2배로 늘려줍니다.\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides)(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    지시사항 2번\n",
    "    아래 내용을 채워 residual_block()을 완성하세요.\n",
    "    '''\n",
    "    # TODO : Projection Shortcut Connection을 구현해보세요.\n",
    "    # 1 x 1 Convolution 연산을 수행하여 Dimension을 2배로 증가시키고\n",
    "    # 입력 Feature map의 size를 1/2로 축소시켜보세요.\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides)(input_tensor)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    # F(x) : x와 Shortcut Connection : shortcut을 더해줍니다.\n",
    "    # TODO : add()와 Activation() 메서드를 사용해서 relu(F(x) + shortcut) 의 형태로 만들어보세요.\n",
    "    x = add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResNet50(img_size):\n",
    "    # 입력 이미지의 Shape을 정해줍니다.\n",
    "    shape = (img_size,img_size,3)\n",
    "    inputs = Input(shape)\n",
    "    \n",
    "    # 입력 영상의 크기를 줄이기 위한 Conv & Max-pooling\n",
    "    x = ZeroPadding2D((3, 3))(inputs)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    # 첫 번째 Residual Block (입력 영상 Size 2배 축소 / Dimension 2배 증가)\n",
    "    x = residual_block(x, 3, [64, 64, 256], strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256])\n",
    "    x = identity_block(x, 3, [64, 64, 256])\n",
    "    \n",
    "    \n",
    "    # 두 번째 Residual Block (입력 영상 Size 2배 축소 / Dimension 2배 증가)\n",
    "    x = residual_block(x, 3, [128, 128, 512])\n",
    "    x = identity_block(x, 3, [128, 128, 512])\n",
    "    x = identity_block(x, 3, [128, 128, 512])\n",
    "    x = identity_block(x, 3, [128, 128, 512])\n",
    "    \n",
    "    # 세 번째 Residual Block (입력 영상 Size 2배 축소 / Dimension 2배 증가)\n",
    "    x = residual_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    \n",
    "    # 네 번째 Residual Block (입력 영상 Size 2배 축소 / Dimension 2배 증가)\n",
    "    x = residual_block(x, 3, [512, 512, 2048])\n",
    "    x = identity_block(x, 3, [512, 512, 2048])\n",
    "    x = identity_block(x, 3, [512, 512, 2048])\n",
    "\n",
    "    # 마지막단에서 FC layer를 쓰지 않고 단순히 Averaging 합니다.\n",
    "    x = AveragePooling2D((7, 7))(x)\n",
    "    # x = GlobalAveragePooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    # 1000개의 Class 구분\n",
    "    x = Dense(43, activation='softmax')(x)\n",
    "    \n",
    "    # 모델 구성\n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "    \n",
    "\n",
    "def main():\n",
    "    \n",
    "    train_images, test_images, train_labels, test_labels = get_images_and_preprocessing(224)\n",
    "\n",
    "    print(train_images.shape)\n",
    "    print(type(train_images))\n",
    "    \n",
    "    \n",
    "    # 지시사항 2에서 설정한 모델을 불러옵니다.\n",
    "    model = ResNet50(224)\n",
    "    \n",
    "    # 모델의 구조를 확인합니다.\n",
    "    model.summary()\n",
    "    \n",
    "    # 컴파일러를 설정합니다.\n",
    "    optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "    model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    # fit 함수를 사용하여 모델을 학습합니다.\n",
    "    # 학습 수행 시 정보는 history에 저장합니다.\n",
    "    history = model.fit(train_images,train_labels, epochs=5, batch_size=512, validation_data=(test_images, test_labels), verbose = 2)\n",
    "    \n",
    "    # evaluate 함수를 사용하여 테스트 데이터의 결과값을 저장합니다.\n",
    "    loss, test_acc = model.evaluate(test_images,test_labels, verbose=2)\n",
    "    \n",
    "    print('\\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))\n",
    "#     print('예측한 Test Data 클래스 : ',model.predict_classes(test_images)[:10])\n",
    "    \n",
    "    Visualize([('ResNet', history)], 'loss')\n",
    "     \n",
    "#     Plotter(test_images, model)\n",
    "    \n",
    "    return test_acc\n",
    "\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "빠름 : CNN, ResNet50     \n",
    "느림 : VGGNet   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

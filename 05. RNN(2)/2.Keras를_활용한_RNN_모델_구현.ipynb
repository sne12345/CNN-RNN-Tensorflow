{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 32)          32000     \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 5)                 190       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 32,196\n",
      "Trainable params: 32,196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 32)           32000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 5)                 760       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 32,766\n",
      "Trainable params: 32,766\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 300, 32)           32000     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 5)                 585       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 32,591\n",
      "Trainable params: 32,591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "98/98 - 5s - loss: 0.6135 - acc: 0.6781\n",
      "Epoch 2/3\n",
      "98/98 - 4s - loss: 0.5212 - acc: 0.7780\n",
      "Epoch 3/3\n",
      "98/98 - 4s - loss: 0.4883 - acc: 0.7919\n",
      "Epoch 1/3\n",
      "98/98 - 9s - loss: 0.6600 - acc: 0.6534\n",
      "Epoch 2/3\n",
      "98/98 - 7s - loss: 0.5157 - acc: 0.7979\n",
      "Epoch 3/3\n",
      "98/98 - 7s - loss: 0.4646 - acc: 0.8178\n",
      "Epoch 1/3\n",
      "98/98 - 9s - loss: 0.6746 - acc: 0.5972\n",
      "Epoch 2/3\n",
      "98/98 - 8s - loss: 0.6097 - acc: 0.6734\n",
      "Epoch 3/3\n",
      "98/98 - 7s - loss: 0.5121 - acc: 0.7541\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.4776 - acc: 0.7937\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.4528 - acc: 0.8113\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.4390 - acc: 0.8067\n",
      "\n",
      "Test Accuracy_simple rnn:  [0.4775678813457489, 0.793666660785675]\n",
      "Test Accuracy_lstm:  [0.4527674913406372, 0.8113333582878113]\n",
      "Test Accuracy_gru:  [0.4389747679233551, 0.8066666722297668]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding, SimpleRNN\n",
    "\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# np.load.__defaults__=(None, False, True, 'ASCII')\n",
    "np_load_old = np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "# 데이터를 불러오고 전처리하는 함수입니다.\n",
    "\n",
    "def load_data(n_of_training_ex, n_of_testing_ex, max_review_length):\n",
    "    \n",
    "    PATH = \"./data/\"\n",
    "    \n",
    "    X_train = np.load(PATH + \"X_train.npy\")[:n_of_training_ex]\n",
    "    y_train = np.load(PATH + \"y_train.npy\")[:n_of_training_ex]\n",
    "    X_test = np.load(PATH + \"X_test.npy\")[:n_of_testing_ex]\n",
    "    y_test = np.load(PATH + \"y_test.npy\")[:n_of_testing_ex]\n",
    "    \n",
    "    X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "    X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "    \n",
    "'''\n",
    "지시사항 1번\n",
    "SimpleRNN을 적용할 하나의 모델을 자유롭게 생성합니다.\n",
    "'''\n",
    "    \n",
    "def SimpleRNN(embedding_vector_length, max_review_length):\n",
    "    \n",
    "    \n",
    "    print(embedding_vector_length)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Embedding(input_dim=1000, output_dim=embedding_vector_length))\n",
    "    model.add(tf.keras.layers.SimpleRNN(units=5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "'''\n",
    "지시사항 2번\n",
    "LSTM을 적용할 하나의 모델을 자유롭게 생성합니다.\n",
    "'''\n",
    "\n",
    "def LSTM(embedding_vector_length, max_review_length):\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Embedding(input_dim=1000, output_dim=embedding_vector_length, input_length=max_review_length))\n",
    "    model.add(tf.keras.layers.LSTM(units=5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "'''\n",
    "지시사항 3번\n",
    "GRU를 적용할 하나의 모델을 자유롭게 생성합니다.\n",
    "'''\n",
    "\n",
    "def GRU(embedding_vector_length, max_review_length):\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Embedding(input_dim=1000, output_dim=embedding_vector_length, input_length=max_review_length))\n",
    "    model.add(tf.keras.layers.GRU(units=5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "'''\n",
    "지시사항 4번\n",
    "세 모델을 불러온 후 학습시키고 테스트 데이터에 대해 평가합니다.\n",
    "\n",
    "   Step01. SimpleRNN, LSTM, GRU 함수를 이용해 세 모델을 불러옵니다.\n",
    "   \n",
    "   Step02. 세 모델의 손실 함수, 최적화 알고리즘, 평가 방법을 설정합니다.\n",
    "   \n",
    "   Step03. 세 모델의 구조를 확인하는 코드를 작성합니다.\n",
    "   \n",
    "   Step04. 세 모델을 각각 학습시킵니다. 검증용 데이터는 설정하지 않습니다.\n",
    "           세 모델 모두 'epochs'는 3, 'batch_size'는 256으로 설정합니다.\n",
    "   \n",
    "   Step05. 세 모델을 테스트하고 각각의 Test Accuracy 값을 출력합니다. \n",
    "           셋 중 어느 모델의 성능이 가장 좋은지 확인해보세요.\n",
    "'''\n",
    "\n",
    "def main():\n",
    "\n",
    "    max_review_length = 300\n",
    "    embedding_vector_length = 32\n",
    "\n",
    "    n_of_training_ex = 25000\n",
    "    n_of_testing_ex = 3000\n",
    "\n",
    "    X_train, y_train, X_test, y_test = load_data(n_of_training_ex, n_of_testing_ex, max_review_length)\n",
    "\n",
    "\n",
    "    # 모델 만들기\n",
    "    model_simple_rnn = SimpleRNN(embedding_vector_length, max_review_length)\n",
    "    model_lstm = LSTM(embedding_vector_length, max_review_length)\n",
    "    model_gru = GRU(embedding_vector_length, max_review_length)\n",
    "\n",
    "\n",
    "    # 컴파일\n",
    "    model_simple_rnn.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "    model_lstm.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "    model_gru.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    # 모델 구조 출력하기\n",
    "    model_simple_rnn.summary()\n",
    "    model_lstm.summary()\n",
    "    model_gru.summary()\n",
    "    \n",
    "    # 모델 학습시키기\n",
    "    history_simple_rnn = model_simple_rnn.fit(X_train, y_train, epochs=3, batch_size=256,verbose=2)\n",
    "    history_lstm = model_lstm.fit(X_train, y_train, epochs=3, batch_size=256,verbose=2)\n",
    "    history_gru = model_gru.fit(X_train, y_train, epochs=3, batch_size=256,verbose=2)\n",
    "\n",
    "    # 모델 평가하기\n",
    "    scores_simple_rnn = model_simple_rnn.evaluate(X_test,y_test)\n",
    "    scores_lstm = model_lstm.evaluate(X_test,y_test)\n",
    "    scores_gru = model_gru.evaluate(X_test,y_test)\n",
    "\n",
    "    print('\\nTest Accuracy_simple rnn: ', scores_simple_rnn)\n",
    "    print('Test Accuracy_lstm: ', scores_lstm)\n",
    "    print('Test Accuracy_gru: ', scores_gru)\n",
    "\n",
    "    return model_simple_rnn, model_lstm, model_gru\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

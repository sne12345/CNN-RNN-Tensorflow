{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“옥련아, 옥련아 옥련아 옥련아, 죽었느냐 살았느냐', ' 죽었거든 죽은 얼굴이라도 한번 다시 만나보자', ' 옥련아 옥련아, 살았거든 어미 애를 그만 쓰이고 어서 바삐 내 눈에 보이게 하여라', ' 옥련아, 총에 맞아 죽었느냐, 창에 찔려 죽었느냐, 사람에게 밟혀 죽었느냐', ' 어리고 고운 살에 가시가 박힌 것을 보아도 어미 된 이내 마음에 내 살이 지겹게 아프던 내 마음이라', ' 오늘 아침에 집에서 떠나올 때에 옥련이가 내 앞에 서서 아장아장 걸어다니면서, 어머니 어서 갑시다 하던 옥련이가 어디로 갔느냐', '”하면서 옥련이를 찾으려고 골몰한 정신에, 옥련이보다 열 갑절 스무 갑절 더 소중하게 생각하는사람을 잃고도 모르고 옥련이만 부르며 다니다가 목이 쉬고 기운이 탈진하여 산비탈 잔디풀 위에 털썩 주저앉았다가 혼자말로 옥련 아버지는 옥련이 찾으려고 저 건너 산 밑으로 가더니 어디까지 갔누 하며 옥련이를 찾던 마음이 홀지에 변하여 옥련 아버지를 기다린다', '']\n",
      "문장으로 구분된 5번째 문단:  ['“옥련아, 옥련아 옥련아 옥련아, 죽었느냐 살았느냐', '죽었거든 죽은 얼굴이라도 한번 다시 만나보자', '옥련아 옥련아, 살았거든 어미 애를 그만 쓰이고 어서 바삐 내 눈에 보이게 하여라', '옥련아, 총에 맞아 죽었느냐, 창에 찔려 죽었느냐, 사람에게 밟혀 죽었느냐', '어리고 고운 살에 가시가 박힌 것을 보아도 어미 된 이내 마음에 내 살이 지겹게 아프던 내 마음이라', '오늘 아침에 집에서 떠나올 때에 옥련이가 내 앞에 서서 아장아장 걸어다니면서, 어머니 어서 갑시다 하던 옥련이가 어디로 갔느냐', '”하면서 옥련이를 찾으려고 골몰한 정신에, 옥련이보다 열 갑절 스무 갑절 더 소중하게 생각하는사람을 잃고도 모르고 옥련이만 부르며 다니다가 목이 쉬고 기운이 탈진하여 산비탈 잔디풀 위에 털썩 주저앉았다가 혼자말로 옥련 아버지는 옥련이 찾으려고 저 건너 산 밑으로 가더니 어디까지 갔누 하며 옥련이를 찾던 마음이 홀지에 변하여 옥련 아버지를 기다린다', '']\n",
      "\n",
      "띄어쓰기로 구분된 문장 (5번째 문단의 4번째 문장):  ['옥련아,', '총에', '맞아', '죽었느냐,', '창에', '찔려', '죽었느냐,', '사람에게', '밟혀', '죽었느냐']\n",
      "\n",
      "형태소 별로 구분된 문장 (5번째 문단의 4번째 문장):  ['옥련', '아', ',', '총', '에', '맞아', '죽었느냐', ',', '창', '에', '찔려', '죽었느냐', ',', '사람', '에게', '밟혀', '죽었느냐']\n",
      "\n",
      "형태소와 그에 따른 품사로 분류된 문장 (5번째 문단의 4번째 문장):  [('옥련', 'Noun'), ('아', 'Josa'), (',', 'Punctuation'), ('총', 'Noun'), ('에', 'Josa'), ('맞아', 'Verb'), ('죽었느냐', 'Verb'), (',', 'Punctuation'), ('창', 'Noun'), ('에', 'Josa'), ('찔려', 'Verb'), ('죽었느냐', 'Verb'), (',', 'Punctuation'), ('사람', 'Noun'), ('에게', 'Josa'), ('밟혀', 'Verb'), ('죽었느냐', 'Verb')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from konlpy.tag import Okt \n",
    "\n",
    "def load_data(path):\n",
    "    with open(path, 'r') as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "'''\n",
    "지시사항 1번\n",
    "'문서'를 '문단'의 리스트로 변환하는 함수 doc2para를 완성합니다.\n",
    "\n",
    "   Step01. 문장의 마침표(.) 뒤에 있는 개행 표시(\\n)를 기준으로 \n",
    "           문서 내 글들을 리스트 요소 즉, 문단으로 나눕니다.\n",
    "           \n",
    "   Step02. 나누어진 글들 중 마지막 글자가 \".\"인 경우만 \n",
    "           문단이 나누어진 것으로 보고 그 외의 문장들은 서로 \n",
    "           병합하여 줍니다.\n",
    "'''\n",
    "\n",
    "def doc2para(writing):\n",
    "    \n",
    "    paragraphs = []\n",
    "    \n",
    "    splited = writing.strip().split(\"\\n\")\n",
    "    para = \"\"\n",
    "    \n",
    "    for word in splited:\n",
    "        if len(word) > 0:\n",
    "            if word[-1] == \".\":\n",
    "                para += word\n",
    "                paragraphs.append(para)\n",
    "                para = \"\"\n",
    "            else:\n",
    "                para += word\n",
    "            \n",
    "    # print(paragraphs[0:5])\n",
    "    \n",
    "    return paragraphs\n",
    "\n",
    "'''\n",
    "지시사항 2번\n",
    "'문단'을 '문장'의 리스트로 변환하는 함수 para2sen을 완성합니다.\n",
    "\n",
    "   Step01. 문단을 \".\"으로 나누어 리스트로 만들고, \n",
    "           변수 sentences에 저장합니다.\n",
    "           \n",
    "   Step02. sentences 내 문장들에 대해서 \"?\"로 재분할 한 후, \n",
    "           ndarray.flatten()을 활용하여 재분할된 문장이 합쳐질 \n",
    "           수 있도록 리스트로 만들어 줍니다. \n",
    "           (\"!\"에 대해서도 마찬가지로 적용합니다.)\n",
    "'''\n",
    "\n",
    "def para2sen(paragraph):\n",
    "    \n",
    "    sentences = []\n",
    "    \n",
    "    # Step01.\n",
    "    sentences = paragraph.strip().split(\".\")\n",
    "    \n",
    "    print(sentences)\n",
    "    \n",
    "    # Step02. \n",
    "    sentences = [sentence.strip().split(\"?\") for sentence in sentences]\n",
    "    sentences = sum(sentences, [])\n",
    "    # sentences = (np.array(sentences)).flatten()\n",
    "    \n",
    "    sentences = [sentence.strip().split(\"!\") for sentence in sentences]\n",
    "    sentences = sum(sentences, [])\n",
    "    # sentences = (np.array(sentences)).flatten()\n",
    "    \n",
    "    sentences = [ sentence.replace('\"','') for sentence in sentences]\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "# 띄어쓰기로 문장을 구분하는 함수\n",
    "\n",
    "def sen2words_byspace(sentence):\n",
    "    \n",
    "    words = []\n",
    "    words = sentence.strip().split(\" \")\n",
    "    \n",
    "    return words\n",
    "\n",
    "'''\n",
    "지시사항 3번\n",
    "    'Twitter()'로 선언된 Tokenizer인 'analyzer'를 이용해 형태소에 따라 \n",
    "    분할된 문장의 리스트를 변수 'morphs'에 저장하는 sen2morph\n",
    "    함수를 완성합니다. Twitter.morphs 메소드를 사용하세요.\n",
    "'''\n",
    "\n",
    "def sen2morph(sentence):\n",
    "    \n",
    "    morphs = []\n",
    "    \n",
    "    analyzer = Twitter()\n",
    "    morphs = analyzer.morphs(sentence)\n",
    "    \n",
    "    return morphs\n",
    "\n",
    "'''\n",
    "지시사항 4번\n",
    "   3번과 같이 'Twitter()'로 선언된 Tokenizer인 'analyzer'를 이용해\n",
    "   형태소와 그에 따른 품사를 분할하는 analyzing_morphs 함수를 완성합니다.\n",
    "   Twitter.pos 메소드를 사용하세요.\n",
    "'''\n",
    "\n",
    "def analyzing_morphs(sentence):\n",
    "\n",
    "    # print(sentence)\n",
    "    \n",
    "    analyzer = Twitter()\n",
    "    \n",
    "    return analyzer.pos(sentence)\n",
    "    \n",
    "# 위에서 정의한 함수들을 바탕으로 문서를 토큰화를 진행합니다.\n",
    "\n",
    "def main():\n",
    "    \n",
    "    DATA_PATH = \"./data/blood_rain.txt\"\n",
    "    \n",
    "    blood_rain = load_data(DATA_PATH)\n",
    "    paragraphs = doc2para(blood_rain)\n",
    "    sentences = para2sen(paragraphs[4])\n",
    "    words_byspace = sen2words_byspace(sentences[3])\n",
    "    words_bymorphs = sen2morph(sentences[3])\n",
    "    morphs_analyzed = analyzing_morphs(sentences[3])\n",
    "    \n",
    "    # 출력을 통해 토큰화가 잘 되었는지 확인합니다.\n",
    "    \n",
    "    print(\"문장으로 구분된 5번째 문단: \", sentences)\n",
    "    print(\"\\n띄어쓰기로 구분된 문장 (5번째 문단의 4번째 문장): \", words_byspace)\n",
    "    print(\"\\n형태소 별로 구분된 문장 (5번째 문단의 4번째 문장): \", words_bymorphs)\n",
    "    print(\"\\n형태소와 그에 따른 품사로 분류된 문장 (5번째 문단의 4번째 문장): \", morphs_analyzed)\n",
    "    \n",
    "    return words_byspace, words_bymorphs, morphs_analyzed\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
